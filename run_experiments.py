#!/usr/bin/env python3
"""
å®éªŒè¿è¡Œè„šæœ¬ï¼šæ‰¹é‡è¿è¡Œä¸åŒé…ç½®çš„å®éªŒ
"""
import subprocess
import sys
import time


def run_command(cmd):
    """è¿è¡Œå‘½ä»¤å¹¶æ‰“å°ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print('='*60)
    
    start_time = time.time()
    result = subprocess.run(cmd, capture_output=False, text=True)
    end_time = time.time()
    
    print(f"\nå‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.1f}ç§’")
    print(f"è¿”å›ç : {result.returncode}")
    
    return result.returncode == 0


def main():
    """è¿è¡Œä¸€ç³»åˆ—å®éªŒ"""
    
    experiments = [
        
        # # TSMixerå®éªŒ
        # {
        #     "name": "TSMixer + FD001 (OneCycle + æ—©åœ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "80",  # å¢åŠ æœ€å¤§epochsï¼Œè®©æ—©åœå†³å®šä½•æ—¶åœæ­¢
        #            "--learning_rate", "0.001",  # é™ä½å­¦ä¹ ç‡
        #            "--tsmixer_layers", "3",  # å‡å°‘å¤æ‚åº¦
        #            "--time_expansion", "3",
        #            "--feat_expansion", "3",
        #            "--dropout", "0.15",  # å¢åŠ æ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"  # 10è½®ä¸æ”¹å–„å°±åœæ­¢
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (Cosineè°ƒåº¦å™¨)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",
        #            "--learning_rate", "0.002",  # é€‚ä¸­çš„åˆå§‹å­¦ä¹ ç‡
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.15",
        #            "--scheduler", "cosine"  # ä½¿ç”¨Cosineè°ƒåº¦å™¨
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (Plateau + æ—©åœ3)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",  # æ›´å¤šepochsé…åˆæ—©åœ
        #            "--learning_rate", "0.002",
        #            "--tsmixer_layers", "4",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.1",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "3"  # æ›´ä¸¥æ ¼çš„æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (æ— æ—©åœå¯¹æ¯”)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "30",  # è¾ƒå°‘epochs
        #            "--learning_rate", "0.001",
        #            "--tsmixer_layers", "3",
        #            "--time_expansion", "3",
        #            "--feat_expansion", "3",
        #            "--dropout", "0.15",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "0"  # ç¦ç”¨æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD002 (å¤æ‚æ•°æ®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.001",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "8",
        #            "--feat_expansion", "6",
        #            "--dropout", "0.2",
        #            "--scheduler", "onecycle"
        #            ]
        # },
        
        # RBM-LSTMå®éªŒ - å¯»æ‰¾æœ€ä¼˜é…ç½®
        # {
        #     "name": "RBM-LSTM-1: åŸºç¡€ä¼˜åŒ–é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "60",
        #            "--learning_rate", "0.001",
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.3",
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "5",
        #            "--rbm_lr", "0.005",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-2: æ›´å¤§æ¨¡å‹",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "96",         # å‡å°batch_sizeé€‚åº”å¤§æ¨¡å‹
        #            "--epochs", "60",
        #            "--learning_rate", "0.0008",  # å¤§æ¨¡å‹ç”¨ç¨å°å­¦ä¹ ç‡
        #            "--rbm_hidden", "256",        # æ›´å¤§çš„RBM
        #            "--lstm_hidden1", "256",      # æ›´å¤§çš„LSTM
        #            "--lstm_hidden2", "128",
        #            "--ff_hidden", "64",          # æ›´å¤§çš„å‰é¦ˆå±‚
        #            "--dropout_lstm", "0.4",      # å¤§æ¨¡å‹éœ€è¦æ›´å¤šæ­£åˆ™åŒ–
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "6",          # æ›´å¤šé¢„è®­ç»ƒ
        #            "--rbm_lr", "0.003",          # æ›´å°çš„RBMå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-3: æ·±å±‚ç½‘ç»œ",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "60",
        #            "--learning_rate", "0.0012",  # ç¨é«˜å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "128",      # ä¸¤å±‚LSTMç›¸åŒå¤§å°
        #            "--ff_hidden", "64",          # æ›´å¤§å‰é¦ˆå±‚
        #            "--dropout_lstm", "0.25",     # ç¨ä½dropout
        #            "--rbm_pool", "mean",         # å°è¯•å‡å€¼æ± åŒ–
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "4",
        #            "--rbm_lr", "0.008",          # ç¨é«˜RBMå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-4: é«˜å­¦ä¹ ç‡é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "160",        # æ›´å¤§batch
        #            "--epochs", "50",
        #            "--learning_rate", "0.0015",  # æ›´é«˜å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.2",      # æ›´ä½dropout
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "3",          # è¾ƒå°‘é¢„è®­ç»ƒè½®æ•°
        #            "--rbm_lr", "0.01",           # è¾ƒé«˜RBMå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-5: æ— é¢„è®­ç»ƒåŸºçº¿",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "60",
        #            "--learning_rate", "0.001",
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.3",
        #            "--rbm_pool", "last",
        #            # ä¸å¯ç”¨RBMé¢„è®­ç»ƒ
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-6: Cosineè°ƒåº¦å™¨",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",             # æ›´å¤šè½®æ•°é…åˆcosine
        #            "--learning_rate", "0.002",   # æ›´é«˜åˆå§‹å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.35",
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "5",
        #            "--rbm_lr", "0.005",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "cosine",      # ä½¿ç”¨cosineè°ƒåº¦å™¨
        #            "--early_stopping", "15"
        #            ]
        #         },
        
        # # TSMixer ä¼˜åŒ–å®éªŒ - åŸºäºæ—¥å¿—åˆ†æ
        # {
        #     "name": "TSMixer-1: æœ€ä¼˜åŸºçº¿é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "60",
        #            "--learning_rate", "0.002",      # éªŒè¯æœ‰æ•ˆçš„é«˜å­¦ä¹ ç‡
        #            "--tsmixer_layers", "4",         # æœ€ä½³å±‚æ•°
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.1",              # è¾ƒä½dropout
        #            "--scheduler", "plateau",        # æœ€ä½³è°ƒåº¦å™¨
        #            "--early_stopping", "5"          # ç¨å¾®å¢åŠ è€å¿ƒå€¼
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-2: å¼ºæ­£åˆ™åŒ–é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",           # å‡å°batch size
        #            "--epochs", "60",
        #            "--learning_rate", "0.0015",     # ç¨ä½å­¦ä¹ ç‡
        #            "--weight_decay", "0.0005",      # å¢å¼ºæƒé‡è¡°å‡
        #            "--tsmixer_layers", "4",
        #            "--time_expansion", "3",         # å‡å°‘å¤æ‚åº¦
        #            "--feat_expansion", "3",
        #            "--dropout", "0.2",              # æ›´å¼ºdropout
        #            "--scheduler", "plateau",
        #            "--early_stopping", "8"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-3: æ·±å±‚ç½‘ç»œé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "192",
        #            "--epochs", "80",
        #            "--learning_rate", "0.001",      # æ·±å±‚ç½‘ç»œç”¨è¾ƒä½å­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",         # æ›´æ·±ç½‘ç»œ
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.15",
        #            "--scheduler", "onecycle",       # æ·±å±‚ç½‘ç»œé€‚åˆonecycle
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-4: ä¿å®ˆè®­ç»ƒé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",     # ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0003",
        #            "--tsmixer_layers", "3",         # è¾ƒæµ…ç½‘ç»œ
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.25",             # å¼ºæ­£åˆ™åŒ–
        #            "--scheduler", "cosine",         # é•¿æœŸè®­ç»ƒç”¨cosine
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-5: é«˜æ•ˆå¿«é€Ÿé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "384",           # å¤§batchå¿«é€Ÿè®­ç»ƒ
        #            "--epochs", "40",                # è¾ƒå°‘è½®æ•°
        #            "--learning_rate", "0.003",      # æ›´é«˜å­¦ä¹ ç‡å¿«é€Ÿæ”¶æ•›
        #            "--weight_decay", "0.0001",
        #            "--tsmixer_layers", "4",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.1",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "3"          # æ¿€è¿›æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-6: FD002å¤æ‚æ•°æ®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.001",      # FD002ç”¨è¾ƒä¿å®ˆå‚æ•°
        #            "--weight_decay", "0.0005",
        #            "--tsmixer_layers", "5",         # å¤æ‚æ•°æ®éœ€è¦æ›´å¤šå±‚
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.2",              # æ›´å¼ºæ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # ============================================================================
        # TSMixer ä¼˜åŒ–å®éªŒ - åŸºäºæ—¥å¿—åˆ†æçš„æ–°é…ç½®
        # ============================================================================
        
        # {
        #     "name": "TSMixer + FD001 (æ·±å±‚ä¼˜åŒ–é…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0012",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "8",         # æ›´æ·±çš„ç½‘ç»œ
        #            "--time_expansion", "6",         # æ›´å¤§çš„æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "4",
        #            "--dropout", "0.12",             # ç²¾è°ƒçš„dropout
        #            "--scheduler", "onecycle",       # æœ€ä½³è°ƒåº¦å™¨
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (å¿«é€Ÿé«˜æ•ˆé…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "512",           # å¤§æ‰¹é‡
        #            "--epochs", "60",
        #            "--learning_rate", "0.004",      # é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.0001",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "5",         # å¹³è¡¡çš„æ‰©å±•
        #            "--dropout", "0.08",             # ä½dropout
        #            "--scheduler", "plateau",
        #            "--early_stopping", "5"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (ææ·±ç½‘ç»œæµ‹è¯•)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "192",
        #            "--epochs", "120",
        #            "--learning_rate", "0.001",
        #            "--weight_decay", "0.0003",
        #            "--tsmixer_layers", "10",        # ææ·±ç½‘ç»œ
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.15",             # é€‚ä¸­æ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # ============================================================================
        # å‰ä¸‰åæœ€ä¼˜é…ç½® - åŸºäº13ä¸ªå®éªŒçš„æ€§èƒ½åˆ†æ
        # ============================================================================
        
        {
            "name": "ğŸ¥‡ TSMixerå† å†›é…ç½® (11.46 RMSE)",
            "cmd": ["python", "train.py", 
                   "--model", "tsmixer", 
                   "--fault", "FD001", 
                   "--batch_size", "384",           # å¤§æ‰¹é‡è®­ç»ƒ
                   "--epochs", "50",
                   "--learning_rate", "0.005",      # æé«˜å­¦ä¹ ç‡
                   "--weight_decay", "0.00005",     # æä½æƒé‡è¡°å‡
                   "--tsmixer_layers", "4",         # è½»é‡ç½‘ç»œ
                   "--time_expansion", "3",         # é€‚ä¸­æ—¶é—´æ‰©å±•
                   "--feat_expansion", "4",         # é€‚ä¸­ç‰¹å¾æ‰©å±•
                   "--dropout", "0.05",             # æä½dropout
                   "--scheduler", "plateau",        # å¹³å°è°ƒåº¦å™¨
                   "--early_stopping", "10"          # æ¿€è¿›æ—©åœ
                   ]
        },
        
        {
            "name": "ğŸ¥ˆ TSMixeräºšå†›é…ç½® (11.69 RMSE)",
            "cmd": ["python", "train.py", 
                   "--model", "tsmixer", 
                   "--fault", "FD001", 
                   "--batch_size", "512",           # è¶…å¤§æ‰¹é‡
                   "--epochs", "60",
                   "--learning_rate", "0.004",      # é«˜å­¦ä¹ ç‡
                   "--weight_decay", "0.0001",      # ä½æƒé‡è¡°å‡
                   "--tsmixer_layers", "5",         # ä¸­ç­‰æ·±åº¦
                   "--time_expansion", "4",         # å¹³è¡¡æ—¶é—´æ‰©å±•
                   "--feat_expansion", "5",         # è¾ƒå¤§ç‰¹å¾æ‰©å±•
                   "--dropout", "0.08",             # ä½dropout
                   "--scheduler", "plateau",        # å¹³å°è°ƒåº¦å™¨
                   "--early_stopping", "10"          # å¿«é€Ÿæ—©åœ
                   ]
        },
        
        {
            "name": "ğŸ¥‰ TSMixerå­£å†›é…ç½® (11.91 RMSE)",
            "cmd": ["python", "train.py", 
                   "--model", "tsmixer", 
                   "--fault", "FD001", 
                   "--batch_size", "256",           # ä¸­ç­‰æ‰¹é‡
                   "--epochs", "100",               # æ›´å¤šè®­ç»ƒè½®æ•°
                   "--learning_rate", "0.0012",     # ç²¾è°ƒå­¦ä¹ ç‡
                   "--weight_decay", "0.0002",      # é€‚ä¸­æƒé‡è¡°å‡
                   "--tsmixer_layers", "8",         # æ·±å±‚ç½‘ç»œ
                   "--time_expansion", "6",         # å¤§æ—¶é—´æ‰©å±•
                   "--feat_expansion", "4",         # é€‚ä¸­ç‰¹å¾æ‰©å±•
                   "--dropout", "0.12",             # é€‚ä¸­dropout
                   "--scheduler", "onecycle",       # OneCycleè°ƒåº¦å™¨
                   "--early_stopping", "12"         # è€å¿ƒæ—©åœ
                   ]
        },
        
        
        
        # {
        #     "name": "RBM-LSTM + FD001 (æ— é¢„è®­ç»ƒåŸºçº¿)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "60",
        #            "--learning_rate", "0.0003",  # è®ºæ–‡å»ºè®®çš„AdamWå­¦ä¹ ç‡
        #            "--rbm_hidden", "64",
        #            "--lstm_hidden1", "64",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "8",
        #            "--dropout_lstm", "0.5",
        #            "--rbm_pool", "last",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "7"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM + FD001 (RBMé¢„è®­ç»ƒ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "30",            # å‡å°‘epochsä¾¿äºæµ‹è¯•
        #            "--learning_rate", "0.0003",
        #            "--rbm_hidden", "64",
        #            "--lstm_hidden1", "64",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "8",
        #            "--dropout_lstm", "0.5",
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",  # å¯ç”¨RBMé¢„è®­ç»ƒ
        #            "--rbm_epochs", "3",      # RBMé¢„è®­ç»ƒè½®æ•°
        #            "--rbm_lr", "0.01",       # RBMé¢„è®­ç»ƒå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",        # å¯¹æ¯”æ•£åº¦æ­¥æ•°
        #            "--scheduler", "plateau",
        #            "--early_stopping", "7"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM + FD001 (å¤§æ¨¡å‹+é¢„è®­ç»ƒ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0002",  # å¤§æ¨¡å‹ç”¨è¾ƒå°å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",         # æ›´å¤§çš„RBMéšè—å±‚
        #            "--lstm_hidden1", "128",       # æ›´å¤§çš„LSTMå±‚
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "16",           # æ›´å¤§çš„å‰é¦ˆå±‚
        #            "--dropout_lstm", "0.6",       # æ›´å¼ºçš„æ­£åˆ™åŒ–
        #            "--rbm_pool", "mean",          # å°è¯•å¹³å‡æ± åŒ–
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "5",           # æ›´å¤šé¢„è®­ç»ƒè½®æ•°
        #            "--rbm_lr", "0.008",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM + FD002 (å¤æ‚æ•°æ®+é¢„è®­ç»ƒ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0002",
        #            "--rbm_hidden", "96",
        #            "--lstm_hidden1", "96",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "12",
        #            "--dropout_lstm", "0.6",       # FD002æ›´å¤æ‚ï¼Œéœ€è¦æ›´å¼ºæ­£åˆ™åŒ–
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "4",
        #            "--rbm_lr", "0.01",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "8"
        #            ]
        # },

        # BiLSTMå®éªŒï¼ˆæ³¨é‡Šæ‰ä»¥ä¾¿ä¸“æ³¨æµ‹è¯•RBM-LSTMï¼‰
        # {
        #     "name": "BiLSTM + FD001 (åŸºç¡€é…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "bilstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "60",
        #            "--learning_rate", "0.001",
        #            "--lstm_hidden", "64",
        #            "--lstm_layers", "2",
        #            "--bidirectional",  # åŒå‘LSTM
        #            "--mlp_hidden", "64",
        #            "--lstm_pool", "last",
        #            "--dropout", "0.1",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "7"
        #            ]
        # },
        
        # {
        #     "name": "BiLSTM + FD001 (æ·±å±‚ç½‘ç»œ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "bilstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0008",
        #            "--lstm_hidden", "128",  # æ›´å¤§çš„éšè—å±‚
        #            "--lstm_layers", "3",    # æ›´å¤šå±‚æ•°
        #            "--bidirectional",
        #            "--mlp_hidden", "128",
        #            "--lstm_pool", "mean",   # å¹³å‡æ± åŒ–
        #            "--dropout", "0.15",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "BiLSTM + FD002 (å¤æ‚æ•°æ®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "bilstm", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0005",
        #            "--lstm_hidden", "96",
        #            "--lstm_layers", "2",
        #            "--bidirectional",
        #            "--mlp_hidden", "96",
        #            "--lstm_pool", "last",
        #            "--dropout", "0.2",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "8"
        #            ]
        # },

        
        # {
        #     "name": "Transformer + FD001 (å°æ¨¡å‹)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "transformer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0003",
        #            "--d_model", "128",
        #            "--nhead", "8",
        #            "--num_layers", "6",
        #            ]
        # },
        
        # {
        #     "name": "Transformer + FD001 (ä¸­ç­‰æ¨¡å‹)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "transformer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "30",
        #            "--learning_rate", "0.0003",
        #            "--d_model", "128",
        #            "--nhead", "4",
        #            "--num_layers", "3",
        #            ]
        # },
        
       
        # {
        #     "name": "Transformer + FD002",
        #     "cmd": ["python", "train.py", 
        #            "--model", "transformer", 
        #            "--fault", "FD002", 
        #            "--batch_size", "256",
        #            "--epochs", "40",  # FD002æ›´å¤æ‚ï¼Œéœ€è¦æ›´å¤šè½®æ¬¡
        #            "--learning_rate", "0.0002",  # ç¨å¾®é™ä½å­¦ä¹ ç‡
        #            "--d_model", "128",
        #            "--nhead", "4",
        #            "--num_layers", "3",
        #            ]
        # }
    ]
    
    print("å¼€å§‹æ‰¹é‡å®éªŒ...")
    results = {}
    
    for i, exp in enumerate(experiments, 1):
        print(f"\n\nğŸš€ å®éªŒ {i}/{len(experiments)}: {exp['name']}")
        
        success = run_command(exp["cmd"])
        results[exp["name"]] = "æˆåŠŸ" if success else "å¤±è´¥"
        
        if not success:
            print(f"âŒ å®éªŒå¤±è´¥: {exp['name']}")
            choice = input("ç»§ç»­ä¸‹ä¸€ä¸ªå®éªŒï¼Ÿ(y/n): ").lower()
            if choice != 'y':
                break
        else:
            print(f"âœ… å®éªŒæˆåŠŸ: {exp['name']}")
    
    # æ‰“å°æ€»ç»“
    print(f"\n\n{'='*60}")
    print("å®éªŒæ€»ç»“:")
    print('='*60)
    for name, status in results.items():
        status_icon = "âœ…" if status == "æˆåŠŸ" else "âŒ"
        print(f"{status_icon} {name}: {status}")


if __name__ == "__main__":
    main()
