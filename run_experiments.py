#!/usr/bin/env python3
"""
å®éªŒè¿è¡Œè„šæœ¬ï¼šæ‰¹é‡è¿è¡Œä¸åŒé…ç½®çš„å®éªŒ
"""
import subprocess
import sys
import time


def run_command(cmd):
    """è¿è¡Œå‘½ä»¤å¹¶æ‰“å°ç»“æœ"""
    print(f"\n{'='*60}")
    print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print('='*60)
    
    start_time = time.time()
    result = subprocess.run(cmd, capture_output=False, text=True)
    end_time = time.time()
    
    print(f"\nå‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.1f}ç§’")
    print(f"è¿”å›ç : {result.returncode}")
    
    return result.returncode == 0


def main():
    """è¿è¡Œä¸€ç³»åˆ—å®éªŒ"""
    
    experiments = [
        # {
        # "name": "FD002 | TSMixer-PTSA + CondGate | L6 C128 k=2 W12 TopK10 Lv1",
        # "cmd": ["python","train.py",
        #     "--model","tsmixer_ptsa_cond","--fault","FD002",
        #     "--batch_size","640","--epochs","180",
        #     "--learning_rate","0.00035","--weight_decay","0.00008",
        #     "--scheduler","cosine","--warmup_epochs","8","--early_stopping","32",
        #     "--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8",
        #     "--hidden_channels","128","--dropout","0.04",
        #     "--ptsa_every_k","2","--ptsa_heads","6","--ptsa_local_window","12","--ptsa_topk","10",
        #     "--ptsa_levels","1","--ptsa_parent_neigh","1","--ptsa_dropout","0.0",
        #     "--distill_type","conv","--distill_stride","2","--reduce_channels","0.95","--drop_path","0.05",
        #     "--cond_dim","3","--eca_kernel","5","--time_kernel","11",
        #     "--val_batch_mul","8"
        # ]
        # },

        # {
        # "name": "ğŸ¯ | PTSA(FD002) HiAcc | L6 C128 k=2 H6 W12 TopK12 Lv1 rC1.0",
        # "cmd": ["python","train.py",
        #     "--model","tsmixer_ptsa","--fault","FD002",
        #     "--batch_size","640","--epochs","180",
        #     "--learning_rate","0.00033","--weight_decay","0.00008",
        #     "--scheduler","cosine","--warmup_epochs","8","--early_stopping","32",
        #     "--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8",
        #     "--hidden_channels","128","--dropout","0.04",
        #     "--ptsa_every_k","2","--ptsa_heads","6",
        #     "--ptsa_local_window","12","--ptsa_topk","12",
        #     "--ptsa_levels","1","--ptsa_parent_neigh","1","--ptsa_dropout","0.0",
        #     "--distill_type","conv","--distill_stride","2","--reduce_channels","1.0",
        #     "--drop_path","0.05",
        #     "--val_batch_mul","8"
        # ]
        # },
        # {
        # "name": "ğŸ”¬ | PTSA(FD002) TopK Sweep | k=2 W12 Lv1 rC0.95",
        # "cmd": ["bash","-lc",
        #     "for K in 8 10 12; do python train.py --model tsmixer_ptsa --fault FD002 \
        #     --batch_size 640 --epochs 180 --learning_rate 0.00035 --weight_decay 0.00008 \
        #     --scheduler cosine --warmup_epochs 8 --early_stopping 32 \
        #     --tsmixer_layers 6 --time_expansion 4 --feat_expansion 8 \
        #     --hidden_channels 128 --dropout 0.04 \
        #     --ptsa_every_k 2 --ptsa_heads 6 --ptsa_local_window 12 --ptsa_topk $K \
        #     --ptsa_levels 1 --ptsa_parent_neigh 1 --ptsa_dropout 0.0 \
        #     --distill_type conv --distill_stride 2 --reduce_channels 0.95 \
        #     --drop_path 0.05 --val_batch_mul 8; done"
        # ]
        # }





        # {
        # "name": "ğŸ§© | FD002-é…æ–¹Aï¼ˆæ›´ç¨³ç¨€ç–ï¼‰| H120 L6 T4x8 W12 TopK10 Lv1 rC0.95",
        # "cmd": ["python","train.py",
        # "--model","tsmixer_ptsa","--fault","FD002",
        # "--batch_size","640","--epochs","180",
        # "--learning_rate","0.00033","--weight_decay","0.00008",
        # "--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8",
        # "--hidden_channels","120","--dropout","0.04",
        # "--scheduler","cosine","--warmup_epochs","8","--early_stopping","32",
        # "--ptsa_every_k","2","--ptsa_heads","6","--ptsa_local_window","12","--ptsa_topk","10",
        # "--ptsa_levels","1","--ptsa_parent_neigh","1",
        # "--distill_type","conv","--distill_stride","2","--reduce_channels","0.95"
        # ]
        # },
        # {
        # "name": "ğŸ§© | FD002-é…æ–¹Bï¼ˆæ›´å®½è§†åŸŸ+5å¤´ï¼‰| H120 L6 T4x8 W14 TopK12 Lv1 rC0.95",
        # "cmd": ["python","train.py",
        # "--model","tsmixer_ptsa","--fault","FD002",
        # "--batch_size","640","--epochs","180",
        # "--learning_rate","0.00032","--weight_decay","0.00008",
        # "--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8",
        # "--hidden_channels","120","--dropout","0.05",
        # "--scheduler","cosine","--warmup_epochs","8","--early_stopping","32",
        # "--ptsa_every_k","2","--ptsa_heads","5","--ptsa_local_window","14","--ptsa_topk","12",
        # "--ptsa_levels","1","--ptsa_parent_neigh","1",
        # "--distill_type","conv","--distill_stride","2","--reduce_channels","0.95"
        # ]
        # },
        # {
        # "name": "ğŸ§© | FD002-å¯¹æ‹ï¼šæ— çˆ¶é‚»åŸŸP | H120 L6 T4x8 W12 TopK10 Lv1 P0",
        # "cmd": ["python","train.py",
        # "--model","tsmixer_ptsa","--fault","FD002",
        # "--batch_size","640","--epochs","180",
        # "--learning_rate","0.00033","--weight_decay","0.00008",
        # "--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8",
        # "--hidden_channels","120","--dropout","0.04",
        # "--scheduler","cosine","--warmup_epochs","8","--early_stopping","32",
        # "--ptsa_every_k","2","--ptsa_heads","6","--ptsa_local_window","12","--ptsa_topk","10",
        # "--ptsa_levels","1","--ptsa_parent_neigh","0",
        # "--distill_type","conv","--distill_stride","2","--reduce_channels","0.95"
        # ]
        # },
        # {
        # "name": "ğŸ§© | FD002-å¤§æœ‰æ•ˆæ‰¹ï¼ˆaccum=2ï¼‰| H120 L6 T4x8 W12 TopK12 Lv1",
        # "cmd": ["python","train.py",
        # "--model","tsmixer_ptsa","--fault","FD002",
        # "--batch_size","640","--epochs","180","--grad_accum","2",
        # "--learning_rate","0.00030","--weight_decay","0.00008",
        # "--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8",
        # "--hidden_channels","120","--dropout","0.04",
        # "--scheduler","cosine","--warmup_epochs","8","--early_stopping","32",
        # "--ptsa_every_k","2","--ptsa_heads","6","--ptsa_local_window","12","--ptsa_topk","12",
        # "--ptsa_levels","1","--ptsa_parent_neigh","1",
        # "--distill_type","conv","--distill_stride","2","--reduce_channels","1.0"
        # ]
        # }


        # {
        # "name": "ğŸ† | Baselineâ€ Best Â· Dropout 0.04",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "â± | Longer Warmup Â· LRå¾®è°ƒ(-) Â· Dropout 0.04",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00030","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","10","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§± | Dilations 1,2,4 Â· æ„Ÿå—é‡å¢å¼º",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # }






    #         {
    #     "name": "ğŸ§© | FEÃ—8 Â· TSL=6 Â· ä¿å®ˆå¼ºåŒ–ï¼šdils=1,2 Â· wd=1e-4 Â· warmup=10",
    #     "cmd": ["python","train.py",
    #     "--model","tsmixer_eca",
    #     "--fault","FD002",
    #     "--use_eca","--eca_kernel","5",
    #     "--use_bitcn","--tcn_kernel","3",
    #     "--tcn_dilations","1,2","--tcn_fuse","mean",
    #     "--batch_size","576",
    #     "--epochs","180",
    #     "--learning_rate","0.00031",
    #     "--weight_decay","0.00010",
    #     "--tsmixer_layers","6",
    #     "--time_expansion","4",
    #     "--feat_expansion","8",
    #     "--dropout","0.05",
    #     "--tcn_dropout","0.10",
    #     "--scheduler","cosine",
    #     "--warmup_epochs","10",
    #     "--early_stopping","32"
    #     ]
    # },
    # {
    #     "name": "ğŸ›°ï¸ | FEÃ—8 Â· TSL=6 Â· è½»æ‰©æ„Ÿå—é‡ï¼šdils=1,2,3 Â· lr=3.3e-4",
    #     "cmd": ["python","train.py",
    #     "--model","tsmixer_eca",
    #     "--fault","FD002",
    #     "--use_eca","--eca_kernel","5",
    #     "--use_bitcn","--tcn_kernel","3",
    #     "--tcn_dilations","1,2,3","--tcn_fuse","mean",
    #     "--batch_size","576",
    #     "--epochs","180",
    #     "--learning_rate","0.00033",
    #     "--weight_decay","0.00012",
    #     "--tsmixer_layers","6",
    #     "--time_expansion","4",
    #     "--feat_expansion","8",
    #     "--dropout","0.05",
    #     "--tcn_dropout","0.10",
    #     "--scheduler","cosine",
    #     "--warmup_epochs","8",
    #     "--early_stopping","32"
    #     ]
    # },
    # {
    #     "name": "ğŸ”§ | FEÃ—8 Â· TSL=6 Â· å‰æ®µåŠ å¯†ï¼šdils=1,2,2 Â· warmup=12 Â· lr=3.0e-4",
    #     "cmd": ["python","train.py",
    #     "--model","tsmixer_eca",
    #     "--fault","FD002",
    #     "--use_eca","--eca_kernel","5",
    #     "--use_bitcn","--tcn_kernel","3",
    #     "--tcn_dilations","1,2,2","--tcn_fuse","mean",
    #     "--batch_size","576",
    #     "--epochs","180",
    #     "--learning_rate","0.00030",
    #     "--weight_decay","0.00012",
    #     "--tsmixer_layers","6",
    #     "--time_expansion","4",
    #     "--feat_expansion","8",
    #     "--dropout","0.04",
    #     "--tcn_dropout","0.10",
    #     "--scheduler","cosine",
    #     "--warmup_epochs","12",
    #     "--early_stopping","32"
    #     ]
    # }
        # {
        # "name": "ğŸ”§A1 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· wd 8e-5 Â· dils 1,2 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§A2 | FEÃ—8 Â· TSL=6 Â· Dropout 0.03 Â· wd 8e-5 Â· dils 1,2 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.03","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§B1 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· wd 6e-5 Â· dils 1,2 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00006","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§B2 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· wd 1e-4 Â· dils 1,2 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00010","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§C1 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· lr 3.2e-4 Â· wd 8e-5 Â· dils 1,2 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§C2 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· lr 3.8e-4 Â· wd 8e-5 Â· dils 1,2 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00038","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§D1 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· wd 8e-5 Â· dils 1,3 Â· mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,3","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§E1 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04 Â· wd 8e-5 Â· dils 1,2 Â· fuse=concat",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","concat","--batch_size","576","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # }
        # {
        # "name": "ğŸ”§ A1 | FEÃ—8 Â· TSL=6 Â· Dropout 0.04",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00033","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ”§ A2 | FEÃ—8 Â· TSL=6 Â· Dropout 0.06",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00033","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.06","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "âš™ï¸ A3 | FEÃ—8 Â· TSL=6 Â· LR 3e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00030","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "âš™ï¸ A4 | FEÃ—8 Â· TSL=6 Â· LR 3.8e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00038","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ“¦ A5 | Batch 768 Â· FEÃ—8 Â· TSL=6",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ“¦ A6 | Batch 768 Â· FEÃ—8 Â· LR 3.2e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ” A7 | ECA k=3 æ¢ç´¢ Â· å…¶ä½™åŒæœ€ä¼˜é‚»åŸŸ",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","3","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§± A8 | FEÃ—10 Â· æ›´å®½ç‰¹å¾æ··åˆ",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","10","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },

        # {
        # "name": "ğŸŒ€ B1 | TCN dilations {1,3}",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,3","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸŒ€ B2 | TCN dilations {1,2,3}",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,3","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§© B3 | TCN kernel=5 Â· dil {1,2}",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","5","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§© B4 | TCN kernel=5 Â· LR 3.2e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","5","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§ª B5 | TCN dilations {1,2,4} Â· LR 3.2e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§ª B6 | æ›´å° WD=1.2e-4â†’8e-5 Â· ä¿ {1,2}",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00008","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },

        # {
        # "name": "ğŸ—ï¸ C1 | å±‚æ•°â†‘ 8 Â· Dropout 0.04 Â· LR 3.2e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00032","--weight_decay","0.00012","--tsmixer_layers","8","--time_expansion","4","--feat_expansion","8","--dropout","0.04","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ—ï¸ C2 | å±‚æ•°â†“ 4 Â· è½»é‡å¿«é€Ÿå¯¹ç…§",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ«§ C3 | æ›´å° Dropout 0.03",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.03","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ«§ C4 | æ›´å¤§ Dropout 0.07 Â· WD 1.4e-4 Â· LR 3.3e-4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00033","--weight_decay","0.00014","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.07","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },

        # {
        # "name": "ğŸ§ª D1 | Ablation å» ECAï¼ˆä»… BiTCN+TSMixerï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§ª D2 | Ablation å» BiTCNï¼ˆä»… ECA+TSMixerï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # }   
        # {
        # "name": "ğŸ† A1 | FEÃ—8 + TSL=6ï¼ˆåŸºçº¿æœ€ä¼˜çº¿ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.10","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ¥‡ A2 | FEÃ—8 + TSL=6 + ä½MixerDropout(0.05)",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ’ª A3 | FEÃ—8 + TSL=6ï¼ˆåŠ å¤§batch=704ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","704","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.10","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸª„ A4 | FEÃ—8 + TSL=6 + ECA=7ï¼ˆç»†ç²’åº¦é€šé“æ³¨æ„ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","7","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "âš¡ B1 | ç®€æ´çº¿ï¼šTSL=4, FEÃ—4, do=0.05, bs=768ï¼ˆå¼ºä¼˜åŒ–èŒƒå¼ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","160","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "âš–ï¸ B2 | ä¸Šæ¡çš„wdæ‰«æï¼šwd=1e-4ï¼ˆå¸¸è§æœ€ç¨³ç‚¹ä¹‹ä¸€ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","160","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§ª B3 | ä¸Šæ¡çš„wdæ‰«æï¼šwd=1.5e-4ï¼ˆè½»å¾®åŠ æ­£åˆ™ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","160","--learning_rate","0.00035","--weight_decay","0.00015","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ†™ B4 | åœ¨B1ä¸Šä»…æ”¹TSL=6ï¼ˆçœ‹ç»“æ„+ä¼˜åŒ–èƒ½å¦å åŠ ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","4","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§­ C1 | æ§åˆ¶å®éªŒï¼šFEÃ—8 + do=0.05ï¼Œä½† dils=1,2,4",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.05","--tcn_dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },

        # {
        # "name": "ğŸ¥‡ ECATSM-FD002-LongRun++: L4 TE4 FE4 dils=1,2 mean (200e)",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","200","--learning_rate","0.0004","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","36"]
        # },
        # {
        # "name": "ğŸ¥ˆ ECATSM-FD002-DilWide-124: L4 TE4 FE4 dils=1,2,4 mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","704","--epochs","180","--learning_rate","0.0004","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ¥‰ ECATSM-FD002-DilWide-1248: æ›´å¤§æ„Ÿå—é‡",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4,8","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","10","--early_stopping","30"]
        # },
        # {
        # "name": "ğŸƒ ECATSM-FD002-DeepMixer-L6: L6 TE4 FE4 dils=1,2 mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","640","--epochs","180","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","10","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§  ECATSM-FD002-DeepWide-L6FE8: L6 TE4 FE8 dils=1,2 mean",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","576","--epochs","160","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","6","--time_expansion","4","--feat_expansion","8","--dropout","0.10","--scheduler","cosine","--warmup_epochs","10","--early_stopping","28"]
        # },
        # {
        # "name": "ğŸŒŠ ECATSM-FD002-LowDrop: dropout=0.05ï¼ˆæ›´å°‘æ­£åˆ™ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","180","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.05","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§Š ECATSM-FD002-HighWD: wd=3e-4ï¼ˆç•¥å¢æƒé‡è¡°å‡ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","160","--learning_rate","0.00035","--weight_decay","0.0003","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","28"]
        # },
        # {
        # "name": "ğŸ“¡ ECATSM-FD002-ECABigger: eca_kernel=7ï¼ˆæ›´å¹³æ»‘é€šé“æ³¨æ„ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","7","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2","--tcn_fuse","mean","--batch_size","768","--epochs","160","--learning_rate","0.0004","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","28"]
        # },
        # {
        # "name": "â• ECATSM-FD002-FuseSum: BiTCN èåˆ=sum",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","sum","--batch_size","704","--epochs","180","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§© ECATSM-FD002-TCNk5: TCN kernel=5ï¼ˆæ›´å®½å·ç§¯æ ¸ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","5","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","640","--epochs","160","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","28"]
        # },
        # {
        # "name": "ğŸª¶ ECATSM-FD002-TCNdrop06: tcn_dropout=0.06ï¼ˆè½»åº¦æ­£åˆ™ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","704","--epochs","180","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--tcn_dropout","0.06","--scheduler","cosine","--warmup_epochs","8","--early_stopping","32"]
        # },
        # {
        # "name": "ğŸ§± ECATSM-FD002-TE6: æ—¶é—´æ··åˆæ›´å¼ºï¼ˆTE=6ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","704","--epochs","160","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","6","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","28"]
        # },
        # {
        # "name": "ğŸ—‚ ECATSM-FD002-FE8: ç‰¹å¾æ··åˆæ›´å¼ºï¼ˆFE=8ï¼‰",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","640","--epochs","160","--learning_rate","0.00035","--weight_decay","0.00012","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","8","--dropout","0.10","--scheduler","cosine","--warmup_epochs","8","--early_stopping","28"]
        # },
        # {
        # "name": "âš™ï¸ ECATSM-FD002-GradAccum2: æ˜¾å­˜å‹å¥½é•¿è·‘",
        # "cmd": ["python","train.py","--model","tsmixer_eca","--fault","FD002","--use_eca","--eca_kernel","5","--use_bitcn","--tcn_kernel","3","--tcn_dilations","1,2,4","--tcn_fuse","mean","--batch_size","384","--grad_accum","2","--epochs","200","--learning_rate","0.00035","--weight_decay","0.0001","--tsmixer_layers","4","--time_expansion","4","--feat_expansion","4","--dropout","0.10","--scheduler","cosine","--warmup_epochs","10","--early_stopping","36"]
        # }








        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-A1: dp=0.25 br=0.10 wd=3e-4 lr=5e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0005", "--weight_decay", "0.0003",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.25", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-A2: dp=0.25 br=0.10 wd=5e-4 lr=5e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0005", "--weight_decay", "0.0005",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.25", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-A3: dp=0.25 br=0.10 wd=3e-4 lr=6e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0006", "--weight_decay", "0.0003",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.25", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-A4: dp=0.25 br=0.10 wd=5e-4 lr=6e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0006", "--weight_decay", "0.0005",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.25", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-A5: dp=0.25 br=0.10 wd=3e-4 lr=7e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0007", "--weight_decay", "0.0003",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.25", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-A6: dp=0.24 br=0.10 wd=5e-4 lr=7e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0007", "--weight_decay", "0.0005",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.24", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-B1: dp=0.28 br=0.12 wd=2e-4 lr=6e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0006", "--weight_decay", "0.0002",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.28", "--pt_branch_dropout", "0.12",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-B2: dp=0.30 br=0.12 wd=1e-4 lr=6e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0006", "--weight_decay", "0.0001",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.30", "--pt_branch_dropout", "0.12",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-B3: dp=0.30 br=0.12 wd=2e-4 lr=5e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0005", "--weight_decay", "0.0002",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.30", "--pt_branch_dropout", "0.12",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-B4: dp=0.30 br=0.12 wd=2e-4 lr=7e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0007", "--weight_decay", "0.0002",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.30", "--pt_branch_dropout", "0.12",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-B5: dp=0.32 br=0.12 wd=2e-4 lr=6e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0006", "--weight_decay", "0.0002",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.32", "--pt_branch_dropout", "0.12",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        # {
        #     "name": "ğŸ’ pTSM-FD002-Micro-B6: dp=0.28 br=0.10 wd=2e-4 lr=6e-4",
        #     "cmd": ["python", "train.py",
        #     "--model", "ptsmixer", "--fault", "FD002",
        #     "--batch_size", "192", "--epochs", "80",
        #     "--learning_rate", "0.0006", "--weight_decay", "0.0002",
        #     "--pt_depth", "8", "--pt_ch_expand", "4",
        #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
        #     "--pt_t_ffn_expand", "1",
        #     "--pt_droppath", "0.28", "--pt_branch_dropout", "0.10",
        #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
        #     "--scheduler", "cosine", "--early_stopping", "18"
        #     ]
        # },
        

    # {
    # "name": "ğŸ’ pTSM-FD002-Narrow-1: best+wdâ†‘",
    # "cmd": ["python", "train.py",
    #     "--model", "ptsmixer", "--fault", "FD002",
    #     "--batch_size", "192", "--epochs", "80",
    #     "--learning_rate", "0.0006", "--weight_decay", "0.0006",
    #     "--pt_depth", "8", "--pt_ch_expand", "4",
    #     "--pt_t_kernel", "9", "--pt_t_dilation", "2",
    #     "--pt_t_ffn_expand", "1",
    #     "--pt_droppath", "0.25", "--pt_branch_dropout", "0.12",
    #     "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #     "--scheduler", "cosine", "--early_stopping", "15"
    # ]
    # },
    # {
    #     "name": "ğŸ’ pTSM-FD002-Narrow-2: dpâ†‘0.28",
    #     "cmd": ["python", "train.py",
    #         "--model", "ptsmixer", "--fault", "FD002",
    #         "--batch_size", "192", "--epochs", "80",
    #         "--learning_rate", "0.0006", "--weight_decay", "0.0005",
    #         "--pt_depth", "8", "--pt_ch_expand", "4",
    #         "--pt_t_kernel", "9", "--pt_t_dilation", "2",
    #         "--pt_t_ffn_expand", "1",
    #         "--pt_droppath", "0.28", "--pt_branch_dropout", "0.12",
    #         "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #         "--scheduler", "cosine", "--early_stopping", "15"
    #     ]
    # },
    # {
    #     "name": "ğŸ’ pTSM-FD002-Narrow-3: lrâ†‘7e-4",
    #     "cmd": ["python", "train.py",
    #         "--model", "ptsmixer", "--fault", "FD002",
    #         "--batch_size", "192", "--epochs", "80",
    #         "--learning_rate", "0.0007", "--weight_decay", "0.0005",
    #         "--pt_depth", "8", "--pt_ch_expand", "4",
    #         "--pt_t_kernel", "9", "--pt_t_dilation", "2",
    #         "--pt_t_ffn_expand", "1",
    #         "--pt_droppath", "0.25", "--pt_branch_dropout", "0.10",
    #         "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #         "--scheduler", "cosine", "--early_stopping", "15"
    #     ]
    # },
    # {
    #     "name": "ğŸ’ pTSM-FD002-Narrow-4: ker=11 å¯¹ç…§",
    #     "cmd": ["python", "train.py",
    #         "--model", "ptsmixer", "--fault", "FD002",
    #         "--batch_size", "192", "--epochs", "80",
    #         "--learning_rate", "0.0006", "--weight_decay", "0.0005",
    #         "--pt_depth", "8", "--pt_ch_expand", "4",
    #         "--pt_t_kernel", "11", "--pt_t_dilation", "2",
    #         "--pt_t_ffn_expand", "1",
    #         "--pt_droppath", "0.25", "--pt_branch_dropout", "0.12",
    #         "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #         "--scheduler", "cosine", "--early_stopping", "15"
    #     ]
    # },
    # {
    #     "name": "ğŸ’ pTSM-FD002-Narrow-5: wd=2e-4 + dp=0.30",
    #     "cmd": ["python", "train.py",
    #         "--model", "ptsmixer", "--fault", "FD002",
    #         "--batch_size", "192", "--epochs", "80",
    #         "--learning_rate", "0.0006", "--weight_decay", "0.0002",
    #         "--pt_depth", "8", "--pt_ch_expand", "4",
    #         "--pt_t_kernel", "9", "--pt_t_dilation", "2",
    #         "--pt_t_ffn_expand", "1",
    #         "--pt_droppath", "0.30", "--pt_branch_dropout", "0.12",
    #         "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #         "--scheduler", "cosine", "--early_stopping", "18"
    #     ]
    # },
    # {
    #     "name": "ğŸ’ pTSM-FD002-Narrow-6: depth=7 ç¨³å¥æ€§",
    #     "cmd": ["python", "train.py",
    #         "--model", "ptsmixer", "--fault", "FD002",
    #         "--batch_size", "192", "--epochs", "80",
    #         "--learning_rate", "0.0006", "--weight_decay", "0.0005",
    #         "--pt_depth", "7", "--pt_ch_expand", "4",
    #         "--pt_t_kernel", "9", "--pt_t_dilation", "2",
    #         "--pt_t_ffn_expand", "1",
    #         "--pt_droppath", "0.24", "--pt_branch_dropout", "0.12",
    #         "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #         "--scheduler", "cosine", "--early_stopping", "15"
    #     ]
    # },
    # {
    #     "name": "ğŸ’ pTSM-FD002-Narrow-7: branch-drop=0.15",
    #     "cmd": ["python", "train.py",
    #         "--model", "ptsmixer", "--fault", "FD002",
    #         "--batch_size", "192", "--epochs", "80",
    #         "--learning_rate", "0.0006", "--weight_decay", "0.0005",
    #         "--pt_depth", "8", "--pt_ch_expand", "4",
    #         "--pt_t_kernel", "9", "--pt_t_dilation", "2",
    #         "--pt_t_ffn_expand", "1",
    #         "--pt_droppath", "0.26", "--pt_branch_dropout", "0.15",
    #         "--pt_pooling", "avg", "--pt_input_dropout", "0.00",
    #         "--scheduler", "cosine", "--early_stopping", "15"
    #     ]
    # }
    #          # 1) åŸºçº¿ï¼ˆä½ å½“å‰æœ€ä¼˜ 15.48ï¼‰
    # {
    #     "name": "pTSM-FD002-BASE-avg_dp0.20",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "8e-4",
    #             "--weight_decay", "2e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "11",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "cosine",
    #             "--early_stopping", "12"]
    # },
    #  # 2) ä»…å¢å¼ºæƒé‡è¡°å‡ï¼ˆå‹æœ«ç«¯è¿‡æ‹Ÿåˆï¼‰
    # {
    #     "name": "pTSM-FD002-wd5e-4_lr8e-4",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "8e-4",
    #             "--weight_decay", "5e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "11",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "cosine",
    #             "--early_stopping", "12"]
    # },
    # # 3) wdâ†‘ + lrâ†“ + plateauï¼ˆæ›´ç¨³çš„å°¾æœŸå¾®è°ƒï¼‰
    # {
    #     "name": "pTSM-FD002-wd5e-4_lr6e-4_plateau",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "6e-4",
    #             "--weight_decay", "5e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "11",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "plateau",
    #             "--early_stopping", "12"]
    # },

    # # 4) æ„Ÿå—é‡å¯¹ç…§ï¼škernel 9 / dilation 2ï¼ˆæ›´å¹³æ»‘ï¼‰
    # {
    #     "name": "pTSM-FD002-ker9_dil2",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "8e-4",
    #             "--weight_decay", "2e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "9",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "cosine",
    #             "--early_stopping", "12"]
    # },

    # # 5) æ„Ÿå—é‡å¯¹ç…§ï¼škernel 7 / dilation 3ï¼ˆæ›´å¤§æœ‰æ•ˆè§†é‡ã€ä½å‚æ•°ï¼‰
    # {
    #     "name": "pTSM-FD002-ker7_dil3",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "8e-4",
    #             "--weight_decay", "2e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "7",
    #             "--pt_t_dilation", "3",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "cosine",
    #             "--early_stopping", "12"]
    # },

    # # 6) æ·±åº¦â†‘ + DropPathâ†‘ï¼ˆè¡¨å¾æ›´å¼º + æ­£åˆ™é…å¥—ï¼‰
    # {
    #     "name": "pTSM-FD002-depth8_dp0.25",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "80",
    #             "--learning_rate", "6e-4",
    #             "--weight_decay", "5e-4",
    #             "--pt_depth", "8",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "9",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.25",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "cosine",
    #             "--early_stopping", "15"]
    # },

    # # 7) é€šé“æ‰©å±•â†‘ï¼ˆch_expand=6ï¼‰ï¼Œä¿ç•™æ­£åˆ™
    # {
    #     "name": "pTSM-FD002-chx6_dp0.20",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "8e-4",
    #             "--weight_decay", "2e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "6",
    #             "--pt_t_kernel", "11",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "cosine",
    #             "--early_stopping", "12"]
    # },

    # # 8) â€œç¨³å¥æ‹‰ä½â€ç»„åˆï¼ˆwdâ†‘ + lrâ†“ + ker9 + plateauï¼‰
    # {
    #     "name": "pTSM-FD002-steady-wd5e-4_lr6e-4_ker9_plateau",
    #     "cmd": ["python", "train.py",
    #             "--model", "ptsmixer",
    #             "--fault", "FD002",
    #             "--batch_size", "192",
    #             "--epochs", "60",
    #             "--learning_rate", "6e-4",
    #             "--weight_decay", "5e-4",
    #             "--pt_depth", "6",
    #             "--pt_ch_expand", "4",
    #             "--pt_t_kernel", "9",
    #             "--pt_t_dilation", "2",
    #             "--pt_t_ffn_expand", "1",
    #             "--pt_droppath", "0.20",
    #             "--pt_branch_dropout", "0.10",
    #             "--pt_pooling", "avg",
    #             "--pt_input_dropout", "0.00",
    #             "--scheduler", "plateau",
    #             "--early_stopping", "12"]
    # },
        
        # ============================================================================
        # TSMixer-SGA æ–°æ¨¡å‹å®éªŒ - å¸¦åŒç»´å¯æ‰©å±•å…¨å±€æ³¨æ„åŠ›çš„TSMixer
        # ============================================================================
        
        # {
        #     "name": "ğŸŸ© FD002-A: æé«˜tokenç²’åº¦ï¼ˆpatch=4ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "4",
        #            "--d_model", "160",
        #            "--depth", "5",
        #            "--token_mlp_dim", "320",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.12",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "1.8",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸ¦ FD002-B: å¤šå¤´åˆ†å·¥ï¼ˆheads=10, æ¸©åº¦2.0ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "5",
        #            "--d_model", "200",
        #            "--depth", "5",
        #            "--token_mlp_dim", "400",
        #            "--channel_mlp_dim", "200",
        #            "--dropout", "0.12",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "10",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "2.0",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸ¨ FD002-C: æ›´ç»†ç²’åº¦ä¸Šé™ï¼ˆpatch=3ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "160",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "3",
        #            "--d_model", "160",
        #            "--depth", "5",
        #            "--token_mlp_dim", "384",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.14",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.14",
        #            "--tokenpool_temperature", "1.9",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸª FD002-D: å¤§å®¹é‡ç¨³æ€ï¼ˆd_modelâ†‘, depthâ†‘ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "160",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0007",
        #            "--weight_decay", "0.00025",
        #            "--patch", "5",
        #            "--d_model", "192",
        #            "--depth", "6",
        #            "--token_mlp_dim", "384",
        #            "--channel_mlp_dim", "192",
        #            "--dropout", "0.13",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "1.7",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "14"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸ¥ FD002-E: æœ«ç«¯æ›´å…³æ³¨ï¼ˆpool=last å¯¹ç…§ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "4",
        #            "--d_model", "160",
        #            "--depth", "5",
        #            "--token_mlp_dim", "320",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.12",
        #            "--cnn_pool", "last",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "1.8",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
    
        
        # ============================================================================
        # MTS-TSMixer å¤šå°ºåº¦æ—¶é—´æ··åˆå®éªŒ - æ–°æ¨¡å‹æµ‹è¯•
        # ============================================================================
        
        # {
        #     "name": "ğŸ”¥ MTS-1: åŸºç¡€4å°ºåº¦é…ç½®ï¼ˆ3-1,3-2,5-3,7-4ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_mts",
        #            "--fault", "FD002",
        #            "--batch_size", "2304",         # ä¼˜åŒ–ï¼šå¢å¤§batch size
        #            "--num_workers", "32",          # ä¼˜åŒ–ï¼šå¢åŠ workers
        #            "--prefetch_factor", "8",       # ä¼˜åŒ–ï¼šå¢åŠ é¢„å–
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "4",        # æ¯ä¸ªå°ºåº¦çš„æ‰©å±•
        #            "--feat_expansion", "6",
        #            "--dropout", "0.12",
        #            "--mts_scales", "3-1,3-2,5-3,7-4",  # 4ä¸ªæ—¶é—´å°ºåº¦
        #            "--mts_gate_hidden", "16",      # é—¨æ§éšè—å±‚
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŒŠ MTS-2: å¯†é›†å°å°ºåº¦ï¼ˆ3-1,3-2,3-3,5-2ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_mts",
        #            "--fault", "FD002",
        #            "--batch_size", "2304",         # ä¼˜åŒ–ï¼šå¢å¤§batch size
        #            "--num_workers", "32",          # ä¼˜åŒ–ï¼šå¢åŠ workers
        #            "--prefetch_factor", "8",       # ä¼˜åŒ–ï¼šå¢åŠ é¢„å–
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "5",
        #            "--feat_expansion", "6",
        #            "--dropout", "0.12",
        #            "--mts_scales", "3-1,3-2,3-3,5-2",  # å¯†é›†å°å·ç§¯æ ¸
        #            "--mts_gate_hidden", "20",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
       

        # ============================================================================
        # TSMixer-MTS-SGA å¤šå°ºåº¦+åŒè½´æ³¨æ„åŠ›å®éªŒ (FD002)
        # ============================================================================
        
        # {
        #     "name": "âš™ï¸ MTS-SGA-1: åçŸ­æœŸæ•æ„Ÿï¼ˆ3-1,5-1,5-2,7-2ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_mts_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "3072",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0011",
        #            "--weight_decay", "0.00018",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.10",
        #            "--mts_scales", "3-1,5-1,5-2,7-2",
        #            "--mts_gate_hidden", "16",
        #            "--mts_sga_time_hidden", "24",
        #            "--mts_sga_feat_hidden", "24",
        #            "--mts_sga_dropout", "0.08",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "âš¡ MTS-SGA-2: å¤§æ„Ÿå—é‡ï¼ˆ5-2,7-3,9-4,11-5ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_mts_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "2048",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0007",
        #            "--weight_decay", "0.00025",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.14",
        #            "--mts_scales", "5-2,7-3,9-4,11-5",
        #            "--mts_gate_hidden", "24",
        #            "--mts_sga_time_hidden", "16",
        #            "--mts_sga_feat_hidden", "16",
        #            "--mts_sga_dropout", "0.06",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "10",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¯ MTS-SGA-3: 3å°ºåº¦è½»é‡ç‰ˆï¼ˆ3-1,5-2,7-3ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_mts_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "3072",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0010",
        #            "--weight_decay", "0.00020",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.10",
        #            "--mts_scales", "3-1,5-2,7-3",
        #            "--mts_gate_hidden", "12",
        #            "--mts_sga_time_hidden", "16",
        #            "--mts_sga_feat_hidden", "16",
        #            "--mts_sga_dropout", "0.05",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ’ª MTS-SGA-4: 5å°ºåº¦æ·±å±‚ç‰ˆï¼ˆ3-1,5-1,5-2,7-2,9-3ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_mts_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "1792",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "120",
        #            "--learning_rate", "0.0006",
        #            "--weight_decay", "0.00030",
        #            "--tsmixer_layers", "8",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "6",
        #            "--dropout", "0.15",
        #            "--mts_scales", "3-1,5-1,5-2,7-2,9-3",
        #            "--mts_gate_hidden", "32",
        #            "--mts_sga_time_hidden", "24",
        #            "--mts_sga_feat_hidden", "24",
        #            "--mts_sga_dropout", "0.08",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "10",
        #            "--early_stopping", "18"
        #            ]
        # },

        # ============================================================================
        # TokenPool-TSMixer çº¯æ³¨æ„åŠ›æ± åŒ–å®éªŒ (FD002)
        # ============================================================================
        
        {
            "name": "ğŸŸ¥ TokenPool-FD002: æœ«ç«¯æ± åŒ–+Plateauè°ƒåº¦å™¨ï¼ˆæœ€ä¼˜é…ç½®ï¼‰",
            "cmd": ["python", "train.py",
                   "--model", "tokenpool",
                   "--fault", "FD002",
                   "--batch_size", "1920",
                   "--epochs", "100",
                   "--learning_rate", "0.0008",
                   "--weight_decay", "0.0002",
                   "--patch", "4",
                   "--d_model", "160",
                   "--depth", "5",
                   "--token_mlp_dim", "320",
                   "--channel_mlp_dim", "160",
                   "--dropout", "0.12",
                   "--cnn_pool", "last",
                   "--tokenpool_heads", "8",
                   "--tokenpool_dropout", "0.12",
                   "--tokenpool_temperature", "1.8",
                   "--num_workers", "32",
                   "--prefetch_factor", "8",
                   "--scheduler", "plateau",
                   "--early_stopping", "12"
                   ]
        },

        # ============================================================================
        # TokenPool-TSMixer-SGA æ³¨æ„åŠ›æ± åŒ–+åŒè½´æ³¨æ„åŠ›å®éªŒ (FD002)
        # ============================================================================
        
        # {
        #     "name": "ğŸ¨ TokenPool-SGA-1: åŸºç¡€é…ç½®ï¼ˆpatch=6, 5 tokensï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "1024",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0001",
        #            "--patch", "6",                  # 30/6=5 tokens
        #            "--d_model", "120",              # 120 % 6 = 0 âœ“
        #            "--depth", "5",
        #            "--token_mlp_dim", "240",
        #            "--channel_mlp_dim", "120",
        #            "--dropout", "0.12",
        #            "--tokenpool_heads", "6",
        #            "--tokenpool_dropout", "0.10",
        #            "--tokenpool_temperature", "1.5",
        #            "--tokenpool_sga_time_hidden", "24",
        #            "--tokenpool_sga_feat_hidden", "24",
        #            "--tokenpool_sga_dropout", "0.06",
        #            "--tokenpool_sga_fuse", "add",
        #            "--tokenpool_sga_every_k", "0",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ”® TokenPool-SGA-2: é«˜æ¸©æ³¨æ„åŠ›ï¼ˆtemp=1.8, æ›´å¹³æ»‘ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "1024",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0001",
        #            "--patch", "5",
        #            "--d_model", "144",
        #            "--depth", "5",
        #            "--token_mlp_dim", "288",
        #            "--channel_mlp_dim", "144",
        #            "--dropout", "0.12",
        #            "--tokenpool_heads", "6",
        #            "--tokenpool_dropout", "0.10",
        #            "--tokenpool_temperature", "1.8",
        #            "--tokenpool_sga_time_hidden", "24",
        #            "--tokenpool_sga_feat_hidden", "24",
        #            "--tokenpool_sga_dropout", "0.06",
        #            "--tokenpool_sga_fuse", "add",
        #            "--tokenpool_sga_every_k", "0",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "âš¡ TokenPool-SGA-3: åˆ†å±‚æ’å…¥SGAï¼ˆevery_k=2ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "896",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "90",
        #            "--learning_rate", "0.0007",
        #            "--weight_decay", "0.00012",
        #            "--patch", "6",
        #            "--d_model", "120",              # 120 % 6 = 0 âœ“
        #            "--depth", "6",
        #            "--token_mlp_dim", "240",
        #            "--channel_mlp_dim", "120",
        #            "--dropout", "0.12",
        #            "--tokenpool_heads", "6",
        #            "--tokenpool_dropout", "0.10",
        #            "--tokenpool_temperature", "1.6",
        #            "--tokenpool_sga_time_hidden", "32",
        #            "--tokenpool_sga_feat_hidden", "32",
        #            "--tokenpool_sga_dropout", "0.08",
        #            "--tokenpool_sga_fuse", "add",
        #            "--tokenpool_sga_every_k", "2",   # æ¯2å±‚æ’å…¥SGA
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "10",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ’ TokenPool-SGA-4: Hadamardèåˆï¼ˆé—¨æ§ä¹˜æ³•ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "1024",
        #            "--num_workers", "32",
        #            "--prefetch_factor", "8",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0001",
        #            "--patch", "6",
        #            "--d_model", "120",              # 120 % 6 = 0 âœ“
        #            "--depth", "5",
        #            "--token_mlp_dim", "240",
        #            "--channel_mlp_dim", "120",
        #            "--dropout", "0.12",
        #            "--tokenpool_heads", "6",
        #            "--tokenpool_dropout", "0.10",
        #            "--tokenpool_temperature", "1.5",
        #            "--tokenpool_sga_time_hidden", "24",
        #            "--tokenpool_sga_feat_hidden", "24",
        #            "--tokenpool_sga_dropout", "0.06",
        #            "--tokenpool_sga_fuse", "hadamard",  # ä½¿ç”¨Hadamardèåˆ
        #            "--tokenpool_sga_every_k", "0",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },

        # ============================================================================
        # TSMixer-SGA-KG çŸ¥è¯†å¼•å¯¼å®éªŒï¼ˆå·²æ³¨é‡Šï¼‰
        # ============================================================================
        
        # {
        #     "name": "ğŸ§  KG-1: FD002åŸºç¡€é…ç½®ï¼ˆÎ»=0.5, weightedæ± åŒ–ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga_kg",
        #            "--fault", "FD002",
        #            "--batch_size", "576",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.12",
        #            "--sga_time_rr", "4",
        #            "--sga_feat_rr", "4",
        #            "--lambda_prior", "0.5",        # å…ˆéªŒæƒé‡å¹³è¡¡
        #            "--sga_dropout", "0.08",
        #            "--kg_pool", "weighted",        # æœ«ç«¯åŠ æƒ
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ”¬ KG-2: å¼ºå…ˆéªŒå¼•å¯¼ï¼ˆÎ»=0.7, æ›´ä¾èµ–ç‰©ç†çŸ¥è¯†ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga_kg",
        #            "--fault", "FD002",
        #            "--batch_size", "576",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.12",
        #            "--sga_time_rr", "4",
        #            "--sga_feat_rr", "4",
        #            "--lambda_prior", "0.7",        # æ›´å¼ºå…ˆéªŒå¼•å¯¼
        #            "--sga_dropout", "0.08",
        #            "--kg_pool", "weighted",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ“Š KG-3: å¼±å…ˆéªŒå¼•å¯¼ï¼ˆÎ»=0.3, æ›´ä¾èµ–æ•°æ®é©±åŠ¨ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga_kg",
        #            "--fault", "FD002",
        #            "--batch_size", "576",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.12",
        #            "--sga_time_rr", "4",
        #            "--sga_feat_rr", "4",
        #            "--lambda_prior", "0.3",        # æ›´å¼±å…ˆéªŒå¼•å¯¼
        #            "--sga_dropout", "0.08",
        #            "--kg_pool", "weighted",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¯ KG-4: æœ«ç«¯èšç„¦ï¼ˆlastæ± åŒ–ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga_kg",
        #            "--fault", "FD002",
        #            "--batch_size", "576",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.12",
        #            "--sga_time_rr", "4",
        #            "--sga_feat_rr", "4",
        #            "--lambda_prior", "0.5",
        #            "--sga_dropout", "0.08",
        #            "--kg_pool", "last",            # ä»…å…³æ³¨æœ€åæ—¶åˆ»
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "8",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "âš¡ KG-5: è½»é‡é«˜æ•ˆï¼ˆæ›´å¤§å‹ç¼©æ¯”rr=6ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga_kg",
        #            "--fault", "FD002",
        #            "--batch_size", "768",          # æ›´å¤§æ‰¹é‡
        #            "--epochs", "80",
        #            "--learning_rate", "0.001",
        #            "--weight_decay", "0.00025",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.10",
        #            "--sga_time_rr", "6",           # æ›´è½»é‡çš„SGA
        #            "--sga_feat_rr", "6",
        #            "--lambda_prior", "0.5",
        #            "--sga_dropout", "0.05",
        #            "--kg_pool", "weighted",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ’ª KG-6: æ·±å±‚å¼ºåŒ–ï¼ˆlayers=8, å¼ºæ­£åˆ™ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga_kg",
        #            "--fault", "FD002",
        #            "--batch_size", "384",          # æ·±å±‚æ¨¡å‹å‡å°æ‰¹é‡
        #            "--epochs", "120",
        #            "--learning_rate", "0.0006",
        #            "--weight_decay", "0.0003",
        #            "--tsmixer_layers", "8",        # æ›´æ·±ç½‘ç»œ
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.15",            # å¼ºæ­£åˆ™åŒ–
        #            "--sga_time_rr", "4",
        #            "--sga_feat_rr", "4",
        #            "--lambda_prior", "0.5",
        #            "--sga_dropout", "0.10",
        #            "--kg_pool", "weighted",
        #            "--scheduler", "cosine",
        #            "--warmup_epochs", "10",
        #            "--early_stopping", "18"
        #            ]
        # },

        # ============================================================================
        # TSMixer-SGA æ—§æ¨¡å‹å®éªŒï¼ˆå·²æ³¨é‡Šï¼‰
        # ============================================================================
        
        # {
        #     "name": "ğŸŸ© TSMixer-SGA-1: FD002åŸºç¡€+SGAï¼ˆç¨³å¥èµ·æ­¥ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "3072",  # å……åˆ†åˆ©ç”¨RTX 3090çš„24GBæ˜¾å­˜
        #            "--epochs", "70",
        #            "--learning_rate", "0.0009",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.12",
        #            "--use_sga",
        #            "--sga_time_rr", "4",
        #            "--sga_feat_rr", "4",
        #            "--sga_dropout", "0.05",
        #            "--sga_pool", "weighted",       # å¤šå·¥å†µæ›´ç¨³
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸš€ TSMixer-SGA-2: æ·±å±‚Mixer + è½»SGAï¼ˆå®¹é‡â†‘ï¼Œé—¨æ§æ›´è½»ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "160",
        #            "--epochs", "90",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.00025",
        #            "--tsmixer_layers", "6",        # æ·±ä¸€äº›
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.12",
        #            "--use_sga",
        #            "--sga_time_rr", "6",           # æ›´å¤§å‹ç¼©æ¯”=æ›´è½»
        #            "--sga_feat_rr", "6",
        #            "--sga_dropout", "0.05",
        #            "--sga_pool", "weighted",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "14"
        #            ]
        # },
        
        # {
        #     "name": "âš¡ TSMixer-SGA-3: ä¸­å±‚Mixer + å¼ºSGAï¼ˆæ›´å¼ºå‰”å™ªï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "176",
        #            "--epochs", "80",
        #            "--learning_rate", "0.00085",
        #            "--weight_decay", "0.0003",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.15",            # æ­£åˆ™æ›´å¼º
        #            "--use_sga",
        #            "--sga_time_rr", "4",           # é—¨æ§æ›´"ç»†"
        #            "--sga_feat_rr", "4",
        #            "--sga_dropout", "0.08",
        #            "--sga_pool", "weighted",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¯ TSMixer-SGA-4: æ± åŒ–ç­–ç•¥å¯¹æ¯”ï¼ˆæœ«ç«¯lastï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "70",
        #            "--learning_rate", "0.0009",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.12",
        #            "--use_sga",
        #            "--sga_time_rr", "5",
        #            "--sga_feat_rr", "5",
        #            "--sga_dropout", "0.06",
        #            "--sga_pool", "last",           # æœ«æœŸRULæ›´æ•æ„Ÿ
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ§ª TSMixer-SGA-5: OneCycleæ”¶æ•›åŠ é€Ÿ + meanæ± åŒ–",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "180",
        #            "--epochs", "70",
        #            "--learning_rate", "0.0010",    # OneCycle å…è®¸ç•¥é«˜å³°å€¼
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "5",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.12",
        #            "--use_sga",
        #            "--sga_time_rr", "6",
        #            "--sga_feat_rr", "6",
        #            "--sga_dropout", "0.05",
        #            "--sga_pool", "mean",           # å¯¹æ¯” weighted/last
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ§° TSMixer-SGA-6: æ— SGAå¯¹ç…§ï¼ˆç¡®è®¤å¢ç›Šï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tsmixer_sga",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "70",
        #            "--learning_rate", "0.0009",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.12",
        #            # ä¸ä½¿ç”¨ --use_sgaï¼ŒéªŒè¯SGAçš„æ•ˆæœ
        #            "--sga_pool", "weighted",       # ä¿æŒå…¶å®ƒè®¾ç½®ä¸€è‡´
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },

        
        # ============================================================================
        # TokenPool çº¯æ³¨æ„åŠ›æ± åŒ–å®éªŒ - æ— CNNå‰ç«¯ï¼Œç›´æ¥å­¦ä¹ æ—¶é—´ç‰¹å¾
        # ============================================================================
        
        # {
        #     "name": "ğŸŸ© FD002-A: æé«˜tokenç²’åº¦ï¼ˆpatch=4ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "4",
        #            "--d_model", "160",
        #            "--depth", "5",
        #            "--token_mlp_dim", "320",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.12",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "1.8",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸ¦ FD002-B: å¤šå¤´åˆ†å·¥ï¼ˆheads=10, æ¸©åº¦2.0ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "5",
        #            "--d_model", "200",
        #            "--depth", "5",
        #            "--token_mlp_dim", "400",
        #            "--channel_mlp_dim", "200",
        #            "--dropout", "0.12",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "10",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "2.0",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸ¨ FD002-C: æ›´ç»†ç²’åº¦ä¸Šé™ï¼ˆpatch=3ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "160",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "3",  
        #            "--d_model", "160",
        #            "--depth", "5",
        #            "--token_mlp_dim", "384",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.14",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.14",
        #            "--tokenpool_temperature", "1.9",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸª FD002-D: å¤§å®¹é‡ç¨³æ€ï¼ˆd_modelâ†‘, depthâ†‘ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "160",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0007",
        #            "--weight_decay", "0.00025",
        #            "--patch", "5",
        #            "--d_model", "192",
        #            "--depth", "6",
        #            "--token_mlp_dim", "384",
        #            "--channel_mlp_dim", "192",
        #            "--dropout", "0.13",
        #            "--cnn_pool", "weighted",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "1.7",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "14"
        #            ]
        # },
        
        # {
        #     "name": "ğŸŸ¥ FD002-E: æœ«ç«¯æ›´å…³æ³¨ï¼ˆpool=last å¯¹ç…§ï¼‰",
        #     "cmd": ["python", "train.py",
        #            "--model", "tokenpool",
        #            "--fault", "FD002",
        #            "--batch_size", "192",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",
        #            "--weight_decay", "0.0002",
        #            "--patch", "4",
        #            "--d_model", "160",
        #            "--depth", "5",
        #            "--token_mlp_dim", "320",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.12",
        #            "--cnn_pool", "last",
        #            "--tokenpool_heads", "8",
        #            "--tokenpool_dropout", "0.12",
        #            "--tokenpool_temperature", "1.8",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
    
        
        # {
        #     "name": "âš¡ TokenPool-3: FD004æé™æŒ‘æˆ˜",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tokenpool", 
        #            "--fault", "FD004", 
        #            "--batch_size", "128",           # FD004æœ€å¤æ‚ï¼Œå°æ‰¹é‡
        #            "--epochs", "100",                # FD004éœ€è¦å……åˆ†è®­ç»ƒ
        #            "--learning_rate", "0.0006",     # FD004ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0003",      # å¼ºæƒé‡è¡°å‡
        #            # TokenPoolå‚æ•° - ä¸ºå¤æ‚æ•°æ®é›†ä¼˜åŒ–
        #            "--patch", "5",                  # ä¿æŒ10ä¸ªtokens
        #            "--d_model", "160",              # æ›´å¤§æ¨¡å‹å®¹é‡
        #            "--depth", "6",                  # æ·±å±‚TSMixer
        #            "--token_mlp_dim", "384",        # å¤§MLP
        #            "--channel_mlp_dim", "192",
        #            "--dropout", "0.15",             # å¼ºdropouté˜²è¿‡æ‹Ÿåˆ
        #            "--cnn_pool", "weighted",        # å…³æ³¨åæœŸç‰¹å¾
        #            "--tokenpool_heads", "8",        # æ›´å¤šæ³¨æ„åŠ›å¤´å¤„ç†å¤æ‚æ¨¡å¼
        #            "--tokenpool_dropout", "0.15",   
        #            "--tokenpool_temperature", "2.0", # æ›´é«˜æ¸©åº¦é˜²å¡Œç¼©
        #            "--scheduler", "cosine",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # ============================================================================
        # CNN-TSMixer vs TSMixer å¯¹æ¯”å®éªŒ - ç›®æ ‡è¶…è¶Š 11.39 RMSE (TSMixeræœ€ä½³)
        # ============================================================================
        
        # {
        #     "name": "ğŸ¯ CNN-TSMixer-1: å¯¹æ ‡å† å†›é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "384",           # å¯¹æ ‡TSMixerå† å†›
        #            "--epochs", "50",
        #            "--learning_rate", "0.005",      # å¯¹æ ‡é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.00005",     # å¯¹æ ‡ä½æƒé‡è¡°å‡
        #            # CNN-TSMixerç‰¹å®šå‚æ•°
        #            "--patch", "5",                  # é€‚ä¸­patch size
        #            "--cnn_channels", "64",
        #            "--cnn_layers", "2",             # è½»é‡CNNå‰ç«¯
        #            "--cnn_kernel", "5",
        #            "--d_model", "128",
        #            "--depth", "4",                  # å¯¹æ ‡TSMixerå±‚æ•°
        #            "--token_mlp_dim", "256",
        #            "--channel_mlp_dim", "128",
        #            "--dropout", "0.05",             # å¯¹æ ‡æä½dropout
        #            "--cnn_pool", "mean",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "ğŸš€ CNN-TSMixer-2: å¢å¼ºCNNå‰ç«¯",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",           # é€‚ä¸­æ‰¹é‡é€‚åº”æ›´å¤æ‚æ¨¡å‹
        #            "--epochs", "60",
        #            "--learning_rate", "0.003",      # ç¨ä½å­¦ä¹ ç‡é€‚åº”å¤æ‚åº¦
        #            "--weight_decay", "0.0001",
        #            # å¼ºåŒ–CNNç‰¹å¾æå–
        #            "--patch", "4",                  # æ›´ç»†ç²’åº¦patch
        #            "--cnn_channels", "80",          # æ›´å¤šCNNé€šé“
        #            "--cnn_layers", "3",             # æ›´æ·±CNN
        #            "--cnn_kernel", "7",             # æ›´å¤§å·ç§¯æ ¸
        #            "--d_model", "160",              # æ›´å¤§æ¨¡å‹ç»´åº¦
        #            "--depth", "4",
        #            "--token_mlp_dim", "320",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.08",             # é€‚å½“å¢åŠ æ­£åˆ™åŒ–
        #            "--cnn_pool", "weighted",        # å…³æ³¨åæœŸç‰¹å¾
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "âš¡ CNN-TSMixer-3: é«˜æ•ˆè½»é‡ç‰ˆ",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "512",           # å¤§æ‰¹é‡å¿«é€Ÿè®­ç»ƒ
        #            "--epochs", "40",
        #            "--learning_rate", "0.006",      # æ›´é«˜å­¦ä¹ ç‡å¿«é€Ÿæ”¶æ•›
        #            "--weight_decay", "0.00003",     # æ›´ä½æƒé‡è¡°å‡
        #            # è½»é‡é«˜æ•ˆé…ç½®
        #            "--patch", "8",                  # å¤§patchå‡å°‘è®¡ç®—
        #            "--cnn_channels", "48",          # è½»é‡CNN
        #            "--cnn_layers", "2",
        #            "--cnn_kernel", "3",             # å°å·ç§¯æ ¸
        #            "--d_model", "96",               # å°æ¨¡å‹ç»´åº¦
        #            "--depth", "3",                  # æµ…å±‚TSMixer
        #            "--token_mlp_dim", "192",
        #            "--channel_mlp_dim", "96",
        #            "--dropout", "0.03",             # æä½dropout
        #            "--cnn_pool", "last",            # å…³æ³¨æœ€ç»ˆçŠ¶æ€
        #            "--scheduler", "plateau",
        #            "--early_stopping", "8"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ”¥ CNN-TSMixer-4: æ·±åº¦æ··åˆæ¶æ„",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "192",           # ä¸­ç­‰æ‰¹é‡é€‚åº”æ·±å±‚ç½‘ç»œ
        #            "--epochs", "80",
        #            "--learning_rate", "0.002",      # æ·±å±‚ç½‘ç»œä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",
        #            # æ·±å±‚æ··åˆæ¶æ„
        #            "--patch", "5",
        #            "--cnn_channels", "96",          # ä¸°å¯ŒCNNç‰¹å¾
        #            "--cnn_layers", "4",             # æ·±å±‚CNN
        #            "--cnn_kernel", "5",
        #            "--d_model", "192",              # å¤§æ¨¡å‹å®¹é‡
        #            "--depth", "6",                  # æ·±å±‚TSMixer
        #            "--token_mlp_dim", "384",
        #            "--channel_mlp_dim", "192",
        #            "--dropout", "0.10",             # é€‚ä¸­æ­£åˆ™åŒ–
        #            "--cnn_pool", "weighted",
        #            "--scheduler", "onecycle",       # æ·±å±‚ç½‘ç»œç”¨onecycle
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¨ CNN-TSMixer-5: ç²¾ç»†è°ƒä¼˜ç‰ˆ",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "320",           # ç²¾å¿ƒé€‰æ‹©çš„æ‰¹é‡å¤§å°
        #            "--epochs", "70",
        #            "--learning_rate", "0.0035",     # ç²¾è°ƒå­¦ä¹ ç‡
        #            "--weight_decay", "0.00008",     # ç²¾è°ƒæƒé‡è¡°å‡
        #            # ç²¾ç»†è°ƒä¼˜å‚æ•°
        #            "--patch", "6",                  # å¹³è¡¡çš„patch size
        #            "--cnn_channels", "72",          # ç²¾è°ƒé€šé“æ•°
        #            "--cnn_layers", "3",
        #            "--cnn_kernel", "6",             # å¶æ•°å·ç§¯æ ¸
        #            "--d_model", "144",              # 144 = 72 * 2
        #            "--depth", "5",                  # ä¸­ç­‰æ·±åº¦
        #            "--token_mlp_dim", "288",        # 144 * 2
        #            "--channel_mlp_dim", "144",
        #            "--dropout", "0.06",             # ç²¾è°ƒdropout
        #            "--cnn_pool", "mean",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "ğŸ† CNN-TSMixer-6: æé™æŒ‘æˆ˜ç‰ˆ",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",           # å°æ‰¹é‡æ”¯æŒå¤§æ¨¡å‹
        #            "--epochs", "100",
        #            "--learning_rate", "0.001",      # ä¿å®ˆå­¦ä¹ ç‡é•¿æœŸè®­ç»ƒ
        #            "--weight_decay", "0.0003",
        #            # æé™é…ç½®
        #            "--patch", "3",                  # æœ€ç»†ç²’åº¦
        #            "--cnn_channels", "128",         # æœ€å¤šCNNé€šé“
        #            "--cnn_layers", "4",             # æ·±å±‚CNN
        #            "--cnn_kernel", "7",             # å¤§å·ç§¯æ ¸
        #            "--d_model", "256",              # æœ€å¤§æ¨¡å‹ç»´åº¦
        #            "--depth", "8",                  # æœ€æ·±TSMixer
        #            "--token_mlp_dim", "512",        # æœ€å¤§MLP
        #            "--channel_mlp_dim", "256",
        #            "--dropout", "0.12",             # å¼ºæ­£åˆ™åŒ–é˜²è¿‡æ‹Ÿåˆ
        #            "--cnn_pool", "weighted",
        #            "--scheduler", "cosine",         # é•¿æœŸè®­ç»ƒç”¨cosine
        #            "--early_stopping", "20"
        #            ]
        # },

        # ============================================================================
        # é—¨æ§CNN-TSMixerå®éªŒ - è‡ªé€‚åº”ç‰¹å¾èåˆæ¶æ„
        # ============================================================================
        
        # {
        #     "name": "ğŸ”¥ é—¨æ§CNN-TSMixer-1: å¯¹æ ‡TSMixerå† å†›",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD001", 
        #            "--batch_size", "384",           # å¯¹æ ‡TSMixerå† å†›é…ç½®
        #            "--epochs", "50",
        #            "--learning_rate", "0.005",      # é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.00005",     # æä½æƒé‡è¡°å‡
        #            # é—¨æ§CNN-TSMixerå‚æ•°
        #            "--patch", "5",                  # é€‚ä¸­patch
        #            "--cnn_channels", "64",          # æ ‡å‡†CNNé€šé“
        #            "--cnn_layers", "2",             # è½»é‡CNNå‰ç«¯
        #            "--cnn_kernel", "3",             # å°å·ç§¯æ ¸ä¿æŒé•¿åº¦
        #            "--d_model", "128",
        #            "--depth", "4",                  # å¯¹æ ‡TSMixerå±‚æ•°
        #            "--token_mlp_dim", "256",
        #            "--channel_mlp_dim", "128",
        #            "--dropout", "0.05",             # æä½dropout
        #            "--cnn_pool", "mean",
        #            "--use_groupnorm",               # ä½¿ç”¨GroupNorm
        #            "--gn_groups", "8",              # 8ç»„GroupNorm
        #            "--scheduler", "plateau",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        

        # ============================================================================
        # é—¨æ§CNN-TSMixeræœ€ä½³é…ç½® - å…¨æ•°æ®é›†æµ‹è¯• (åŸºäºFD001æœ€ä¼˜ç»“æœ11.23 RMSE)
        # ============================================================================
        
        # {
        #     "name": "ğŸ¥‡ é—¨æ§CNN-TSMixeræœ€ä½³é…ç½® + FD001",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD001", 
        #            "--batch_size", "384",           # æœ€ä½³é…ç½®
        #            "--epochs", "50",
        #            "--learning_rate", "0.005",      # é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.00005",     # æä½æƒé‡è¡°å‡
        #            # é—¨æ§CNN-TSMixeræœ€ä½³å‚æ•°
        #            "--patch", "5",                  # æœ€ä½³patch size
        #            "--cnn_channels", "64",          # æœ€ä½³CNNé€šé“æ•°
        #            "--cnn_layers", "2",             # æœ€ä½³CNNå±‚æ•°
        #            "--cnn_kernel", "3",             # æœ€ä½³å·ç§¯æ ¸å¤§å°
        #            "--d_model", "128",              # æœ€ä½³æ¨¡å‹ç»´åº¦
        #            "--depth", "4",                  # æœ€ä½³TSMixerå±‚æ•°
        #            "--token_mlp_dim", "256",        # æœ€ä½³Token MLPç»´åº¦
        #            "--channel_mlp_dim", "128",      # æœ€ä½³Channel MLPç»´åº¦
        #            "--dropout", "0.05",             # æœ€ä½³dropout
        #            "--cnn_pool", "mean",            # æœ€ä½³æ± åŒ–æ–¹å¼
        #            "--use_groupnorm",               # ä½¿ç”¨GroupNorm
        #            "--gn_groups", "8",              # æœ€ä½³GroupNormåˆ†ç»„
        #            "--scheduler", "plateau",        # æœ€ä½³è°ƒåº¦å™¨
        #            "--early_stopping", "10"         # æœ€ä½³æ—©åœç­–ç•¥
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¥‡ é—¨æ§CNN-TSMixeræœ€ä½³é…ç½® + FD002",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD002", 
        #            "--batch_size", "256",           # FD002å¤æ‚æ•°æ®é€‚å½“å‡å°æ‰¹é‡
        #            "--epochs", "60",                # FD002éœ€è¦æ›´å¤šè®­ç»ƒè½®æ•°
        #            "--learning_rate", "0.003",      # FD002ç”¨ç¨ä½å­¦ä¹ ç‡
        #            "--weight_decay", "0.0001",      # FD002å¢åŠ æƒé‡è¡°å‡
        #            # é—¨æ§CNN-TSMixeræœ€ä½³å‚æ•°
        #            "--patch", "5",                  
        #            "--cnn_channels", "64",          
        #            "--cnn_layers", "2",             
        #            "--cnn_kernel", "3",             
        #            "--d_model", "128",              
        #            "--depth", "4",                  
        #            "--token_mlp_dim", "256",        
        #            "--channel_mlp_dim", "128",      
        #            "--dropout", "0.08",             # FD002å¢åŠ dropouté˜²è¿‡æ‹Ÿåˆ
        #            "--cnn_pool", "mean",            
        #            "--use_groupnorm",               
        #            "--gn_groups", "8",              
        #            "--scheduler", "plateau",        
        #            "--early_stopping", "12"         # FD002å¢åŠ æ—©åœè€å¿ƒå€¼
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¥‡ é—¨æ§CNN-TSMixeræœ€ä½³é…ç½® + FD003",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD003", 
        #            "--batch_size", "384",           # FD003ä¸FD001ç±»ä¼¼ï¼Œä½¿ç”¨ç›¸åŒé…ç½®
        #            "--epochs", "50",
        #            "--learning_rate", "0.005",      
        #            "--weight_decay", "0.00005",     
        #            # é—¨æ§CNN-TSMixeræœ€ä½³å‚æ•°
        #            "--patch", "5",                  
        #            "--cnn_channels", "64",          
        #            "--cnn_layers", "2",             
        #            "--cnn_kernel", "3",             
        #            "--d_model", "128",              
        #            "--depth", "4",                  
        #            "--token_mlp_dim", "256",        
        #            "--channel_mlp_dim", "128",      
        #            "--dropout", "0.05",             
        #            "--cnn_pool", "mean",            
        #            "--use_groupnorm",               
        #            "--gn_groups", "8",              
        #            "--scheduler", "plateau",        
        #            "--early_stopping", "10"         
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¥‡ é—¨æ§CNN-TSMixeræœ€ä½³é…ç½® + FD004",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD004", 
        #            "--batch_size", "192",           # FD004æœ€å¤æ‚ï¼Œè¿›ä¸€æ­¥å‡å°æ‰¹é‡
        #            "--epochs", "80",                # FD004éœ€è¦æœ€å¤šè®­ç»ƒè½®æ•°
        #            "--learning_rate", "0.002",      # FD004ç”¨æ›´ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      # FD004å¢åŠ æ›´å¤šæƒé‡è¡°å‡
        #            # é—¨æ§CNN-TSMixeræœ€ä½³å‚æ•°
        #            "--patch", "5",                  
        #            "--cnn_channels", "64",          
        #            "--cnn_layers", "2",             
        #            "--cnn_kernel", "3",             
        #            "--d_model", "128",              
        #            "--depth", "4",                  
        #            "--token_mlp_dim", "256",        
        #            "--channel_mlp_dim", "128",      
        #            "--dropout", "0.10",             # FD004æœ€é«˜dropouté˜²è¿‡æ‹Ÿåˆ
        #            "--cnn_pool", "mean",            
        #            "--use_groupnorm",               
        #            "--gn_groups", "8",              
        #            "--scheduler", "plateau",        
        #            "--early_stopping", "15"         # FD004æœ€é«˜æ—©åœè€å¿ƒå€¼
        #            ]
        # },

        # # ============================================================================
        # # FD002ä¸“é¡¹ä¼˜åŒ–å®éªŒ - é’ˆå¯¹å¤šå·¥å†µå•æ•…éšœæ¨¡å¼çš„æ€§èƒ½æå‡
        # # ============================================================================
        
        # {
        #     "name": "ğŸ¯ FD002ä¼˜åŒ–-1: å¼ºæ­£åˆ™åŒ–é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",           # å‡å°æ‰¹é‡æå‡æ³›åŒ–
        #            "--epochs", "80",                # æ›´å¤šè½®æ•°
        #            "--learning_rate", "0.002",      # æ›´ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0003",      # æ›´å¼ºæƒé‡è¡°å‡
        #            # å¼ºæ­£åˆ™åŒ–å‚æ•°
        #            "--patch", "5",                  
        #            "--cnn_channels", "64",          
        #            "--cnn_layers", "2",             
        #            "--cnn_kernel", "3",             
        #            "--d_model", "128",              
        #            "--depth", "4",                  
        #            "--token_mlp_dim", "256",        
        #            "--channel_mlp_dim", "128",      
        #            "--dropout", "0.15",             # å¤§å¹…å¢åŠ dropout
        #            "--cnn_pool", "mean",            
        #            "--use_groupnorm",               
        #            "--gn_groups", "8",              
        #            "--scheduler", "plateau",        
        #            "--early_stopping", "15"         # æ›´å¤§è€å¿ƒå€¼
        #            ]
        # },
        
        # {
        #     "name": "ğŸš€ FD002ä¼˜åŒ–-2: å¢å¼ºCNNç‰¹å¾æå–",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD002", 
        #            "--batch_size", "192",           # é€‚ä¸­æ‰¹é‡
        #            "--epochs", "70",                
        #            "--learning_rate", "0.0025",     # é€‚ä¸­å­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      
        #            # å¢å¼ºCNNé…ç½®
        #            "--patch", "4",                  # æ›´ç»†ç²’åº¦patch
        #            "--cnn_channels", "96",          # æ›´å¤šCNNé€šé“
        #            "--cnn_layers", "3",             # æ›´æ·±CNNå±‚
        #            "--cnn_kernel", "3",             
        #            "--d_model", "160",              # æ›´å¤§æ¨¡å‹å®¹é‡
        #            "--depth", "5",                  # æ›´æ·±TSMixer
        #            "--token_mlp_dim", "320",        
        #            "--channel_mlp_dim", "160",      
        #            "--dropout", "0.12",             # é€‚ä¸­dropout
        #            "--cnn_pool", "weighted",        # åŠ æƒæ± åŒ–å…³æ³¨åæœŸ
        #            "--use_groupnorm",               
        #            "--gn_groups", "12",             # æ›´å¤šGroupNormç»„
        #            "--scheduler", "onecycle",       # OneCycleè°ƒåº¦å™¨
        #            "--early_stopping", "12"         
        #            ]
        # },
        
        # {
        #     "name": "âš¡ FD002ä¼˜åŒ–-3: ç¨³å®šè®­ç»ƒé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD002", 
        #            "--batch_size", "160",           # ä¸­å°æ‰¹é‡å¹³è¡¡
        #            "--epochs", "100",               # å……è¶³è®­ç»ƒè½®æ•°
        #            "--learning_rate", "0.0015",     # æ›´ç¨³å®šå­¦ä¹ ç‡
        #            "--weight_decay", "0.0001",      
        #            # ç¨³å®šè®­ç»ƒå‚æ•°
        #            "--patch", "6",                  # ç¨å¤§patchå‡å°‘tokenæ•°
        #            "--cnn_channels", "80",          # é€‚ä¸­CNNé€šé“
        #            "--cnn_layers", "2",             
        #            "--cnn_kernel", "3",             
        #            "--d_model", "144",              # ç¨å¤§æ¨¡å‹ç»´åº¦
        #            "--depth", "4",                  
        #            "--token_mlp_dim", "288",        
        #            "--channel_mlp_dim", "144",      
        #            "--dropout", "0.10",             
        #            "--cnn_pool", "mean",            
        #            "--use_groupnorm",               
        #            "--gn_groups", "10",             # é€‚ä¸­GroupNormç»„æ•°
        #            "--scheduler", "cosine",         # Cosineè°ƒåº¦å™¨é•¿æœŸç¨³å®š
        #            "--early_stopping", "20"         # æ›´å¤§è€å¿ƒå€¼é˜²æ—©åœ
        #            ]
        # },

        # ============================================================================
        # FD004é«˜çº§ä¼˜åŒ–é…ç½® - åŸºäºtokenæ•°é‡å’Œæ—¶é—´åˆ†è¾¨ç‡çš„ç²¾ç»†è°ƒä¼˜ï¼ˆå¤šå·¥å†µ+å¤šæ•…éšœï¼‰
        # ============================================================================
        
        # {
        #     "name": "ğŸ¯ FD004-Stable-Conditioned: ç¨³å®š10tokené…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD004", 
        #            "--batch_size", "192",           # FD004æ›´å¤æ‚ï¼Œå‡å°æ‰¹é‡
        #            "--epochs", "80",                # FD004éœ€è¦æ›´å¤šè®­ç»ƒè½®æ•°
        #            "--learning_rate", "0.001",      # FD004ç”¨æ›´ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      # FD004å¢åŠ æƒé‡è¡°å‡
        #            # ç¨³å®š10tokené…ç½® (50/5=10 tokens, FD004çª—å£=50)
        #            "--patch", "5",                  # FD004çª—å£50ï¼Œpatch=5è·å¾—10ä¸ªtokens
        #            "--cnn_channels", "64",
        #            "--cnn_layers", "2",
        #            "--cnn_kernel", "3",
        #            "--d_model", "160",              # é€‚ä¸­æ¨¡å‹ç»´åº¦
        #            "--depth", "5",                  # é€‚ä¸­æ·±åº¦
        #            "--token_mlp_dim", "320",
        #            "--channel_mlp_dim", "160",
        #            "--dropout", "0.15",             # FD004éœ€è¦æ›´å¼ºæ­£åˆ™åŒ–
        #            "--cnn_pool", "weighted",        # åŠ æƒæ± åŒ–å…³æ³¨åæœŸ
        #            "--use_groupnorm",
        #            "--gn_groups", "8",
        #            "--scheduler", "cosine",         # é•¿æœŸç¨³å®šè°ƒåº¦
        #            "--early_stopping", "15"         # FD004éœ€è¦æ›´å¤§è€å¿ƒå€¼
        #            ]
        # },
        
    

        # ============================================================================
        # TSMixer + FD004 ä¸“é¡¹ä¼˜åŒ–é…ç½® - é’ˆå¯¹æœ€å¤æ‚æ•°æ®é›†çš„å‚æ•°è°ƒä¼˜
        # ============================================================================
        
        # {
        #     "name": "ğŸ¯ TSMixer + FD004: å¼ºæ­£åˆ™åŒ–ç¨³å®šé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD004", 
        #            "--batch_size", "128",           # FD004å¤æ‚æ•°æ®ç”¨å°æ‰¹é‡
        #            "--epochs", "100",               # FD004éœ€è¦å……åˆ†è®­ç»ƒ
        #            "--learning_rate", "0.001",      # FD004ç”¨ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0003",      # FD004éœ€è¦å¼ºæƒé‡è¡°å‡
        #            "--tsmixer_layers", "5",         # é€‚ä¸­å±‚æ•°å¹³è¡¡å®¹é‡å’Œè¿‡æ‹Ÿåˆ
        #            "--time_expansion", "6",         # è¾ƒå¤§æ—¶é—´æ‰©å±•å¤„ç†å¤æ‚æ—¶åº
        #            "--feat_expansion", "4",         # é€‚ä¸­ç‰¹å¾æ‰©å±•
        #            "--dropout", "0.20",             # FD004éœ€è¦å¼ºæ­£åˆ™åŒ–é˜²è¿‡æ‹Ÿåˆ
        #            "--scheduler", "cosine",         # é•¿æœŸç¨³å®šè®­ç»ƒ
        #            "--early_stopping", "15"         # FD004éœ€è¦æ›´å¤§è€å¿ƒå€¼
        #            ]
        # },
        
        # {
        #     "name": "ğŸš€ TSMixer + FD004: æ·±å±‚ç½‘ç»œé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD004", 
        #            "--batch_size", "96",            # æ›´å°æ‰¹é‡é€‚åº”æ·±å±‚ç½‘ç»œ
        #            "--epochs", "120",               # æ·±å±‚ç½‘ç»œéœ€è¦æ›´å¤šè®­ç»ƒ
        #            "--learning_rate", "0.0008",     # æ·±å±‚ç½‘ç»œç”¨æ›´ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0004",      # æ·±å±‚ç½‘ç»œå¢åŠ æƒé‡è¡°å‡
        #            "--tsmixer_layers", "8",         # æ›´æ·±çš„ç½‘ç»œ
        #            "--time_expansion", "8",         # æ›´å¤§æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "5",         # æ›´å¤§ç‰¹å¾æ‰©å±•
        #            "--dropout", "0.25",             # æ·±å±‚ç½‘ç»œéœ€è¦æ›´å¼ºæ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",       # æ·±å±‚ç½‘ç»œé€‚åˆOneCycle
        #            "--early_stopping", "20"         # æ·±å±‚ç½‘ç»œéœ€è¦æ›´å¤šè€å¿ƒ
        #            ]
        # },
        
        # {
        #     "name": "âš¡ TSMixer + FD004: é«˜æ•ˆè½»é‡é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD004", 
        #            "--batch_size", "192",           # è½»é‡æ¨¡å‹å¯ç”¨è¾ƒå¤§æ‰¹é‡
        #            "--epochs", "80",                # è½»é‡æ¨¡å‹è®­ç»ƒæ›´å¿«
        #            "--learning_rate", "0.0015",     # è½»é‡æ¨¡å‹å¯ç”¨ç¨é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      # é€‚ä¸­æƒé‡è¡°å‡
        #            "--tsmixer_layers", "3",         # è¾ƒæµ…ç½‘ç»œ
        #            "--time_expansion", "4",         # é€‚ä¸­æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "3",         # é€‚ä¸­ç‰¹å¾æ‰©å±•
        #            "--dropout", "0.15",             # é€‚ä¸­æ­£åˆ™åŒ–
        #            "--scheduler", "plateau",        # å¿«é€Ÿå“åº”è°ƒåº¦å™¨
        #            "--early_stopping", "12"         # é€‚ä¸­æ—©åœè€å¿ƒ
        #            ]
        # },
        
        # {
        #     "name": "ğŸš€ FD004-Deeper-Token12: æ·±åº¦12tokené…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD004", 
        #            "--batch_size", "160",           # FD004æ·±å±‚æ¨¡å‹ç”¨æ›´å°æ‰¹é‡
        #            "--epochs", "90",                # FD004éœ€è¦æ›´å¤šè½®æ•°
        #            "--learning_rate", "0.0008",     # FD004æ·±å±‚æ¨¡å‹æ›´ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      # å¢åŠ æƒé‡è¡°å‡
        #            # æ·±åº¦12tokené…ç½® (50//4=12 tokens, T_eff=48)
        #            "--patch", "4",                  # æ›´ç»†ç²’åº¦patchè·å¾—12ä¸ªtokens
        #            "--cnn_channels", "80",          # æ›´å¤šCNNé€šé“
        #            "--cnn_layers", "3",             # æ›´æ·±CNNå±‚
        #            "--cnn_kernel", "3",
        #            "--d_model", "192",              # æ›´å¤§æ¨¡å‹å®¹é‡
        #            "--depth", "6",                  # æ›´æ·±TSMixer
        #            "--token_mlp_dim", "384",
        #            "--channel_mlp_dim", "192",
        #            "--dropout", "0.18",             # FD004æ·±å±‚æ¨¡å‹éœ€è¦æ›´å¼ºæ­£åˆ™åŒ–
        #            "--cnn_pool", "weighted",        # æœ«ç«¯æ•æ„Ÿæ± åŒ–
        #            "--use_groupnorm",
        #            "--gn_groups", "10",             # æ›´å¤šGroupNormç»„
        #            "--scheduler", "cosine",
        #            "--early_stopping", "18"         # FD004æ·±å±‚æ¨¡å‹éœ€è¦æ›´å¤šè€å¿ƒ
        #            ]
        # },
        
        # {
        #     "name": "âš¡ FD004-Light-Fast: è½»é‡16tokené«˜æ•ˆé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer_gated", 
        #            "--fault", "FD004", 
        #            "--batch_size", "224",           # FD004è½»é‡ç‰ˆé€‚ä¸­æ‰¹é‡
        #            "--epochs", "70",                # FD004éœ€è¦æ›´å¤šè½®æ•°
        #            "--learning_rate", "0.0012",     # FD004ç¨ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      # FD004å¢åŠ æ­£åˆ™åŒ–
        #            # è½»é‡16tokené…ç½® (50//3=16 tokens, T_eff=48)
        #            "--patch", "3",                  # å°patchè·å¾—16ä¸ªtokens
        #            "--cnn_channels", "64",          # è½»é‡CNNé€šé“
        #            "--cnn_layers", "2",
        #            "--cnn_kernel", "3",
        #            "--d_model", "144",              # å¹³è¡¡çš„æ¨¡å‹ç»´åº¦
        #            "--depth", "5",                  # é€‚ä¸­æ·±åº¦
        #            "--token_mlp_dim", "288",
        #            "--channel_mlp_dim", "144",
        #            "--dropout", "0.20",             # FD004è½»é‡æ¨¡å‹éœ€è¦æ›´å¼ºdropout
        #            "--cnn_pool", "weighted",
        #            "--use_groupnorm",
        #            "--gn_groups", "8",
        #            "--scheduler", "plateau",        # å¿«é€Ÿå“åº”çš„plateauè°ƒåº¦
        #            "--early_stopping", "15"         # FD004éœ€è¦æ›´å¤šè€å¿ƒ
        #            ]
        # },
        
        # # TSMixerå®éªŒ
        # {
        #     "name": "TSMixer + FD001 (OneCycle + æ—©åœ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "80",  # å¢åŠ æœ€å¤§epochsï¼Œè®©æ—©åœå†³å®šä½•æ—¶åœæ­¢
        #            "--learning_rate", "0.001",  # é™ä½å­¦ä¹ ç‡
        #            "--tsmixer_layers", "3",  # å‡å°‘å¤æ‚åº¦
        #            "--time_expansion", "3",
        #            "--feat_expansion", "3",
        #            "--dropout", "0.15",  # å¢åŠ æ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"  # 10è½®ä¸æ”¹å–„å°±åœæ­¢
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (Cosineè°ƒåº¦å™¨)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",
        #            "--learning_rate", "0.002",  # é€‚ä¸­çš„åˆå§‹å­¦ä¹ ç‡
        #            "--tsmixer_layers", "6",
        #            "--time_expansion", "6",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.15",
        #            "--scheduler", "cosine"  # ä½¿ç”¨Cosineè°ƒåº¦å™¨
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (Plateau + æ—©åœ3)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",  # æ›´å¤šepochsé…åˆæ—©åœ
        #            "--learning_rate", "0.002",
        #            "--tsmixer_layers", "4",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.1",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "3"  # æ›´ä¸¥æ ¼çš„æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (æ— æ—©åœå¯¹æ¯”)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "30",  # è¾ƒå°‘epochs
        #            "--learning_rate", "0.001",
        #            "--tsmixer_layers", "3",
        #            "--time_expansion", "3",
        #            "--feat_expansion", "3",
        #            "--dropout", "0.15",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "0"  # ç¦ç”¨æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD002 (å¤æ‚æ•°æ®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.001",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "8",
        #            "--feat_expansion", "6",
        #            "--dropout", "0.2",
        #            "--scheduler", "onecycle"
        #            ]
        # },
        
        # RBM-LSTMå®éªŒ - å¯»æ‰¾æœ€ä¼˜é…ç½®
        # {
        #     "name": "RBM-LSTM-1: åŸºç¡€ä¼˜åŒ–é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "60",
        #            "--learning_rate", "0.001",
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.3",
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "5",
        #            "--rbm_lr", "0.005",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-2: æ›´å¤§æ¨¡å‹",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "96",         # å‡å°batch_sizeé€‚åº”å¤§æ¨¡å‹
        #            "--epochs", "60",
        #            "--learning_rate", "0.0008",  # å¤§æ¨¡å‹ç”¨ç¨å°å­¦ä¹ ç‡
        #            "--rbm_hidden", "256",        # æ›´å¤§çš„RBM
        #            "--lstm_hidden1", "256",      # æ›´å¤§çš„LSTM
        #            "--lstm_hidden2", "128",
        #            "--ff_hidden", "64",          # æ›´å¤§çš„å‰é¦ˆå±‚
        #            "--dropout_lstm", "0.4",      # å¤§æ¨¡å‹éœ€è¦æ›´å¤šæ­£åˆ™åŒ–
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "6",          # æ›´å¤šé¢„è®­ç»ƒ
        #            "--rbm_lr", "0.003",          # æ›´å°çš„RBMå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-3: æ·±å±‚ç½‘ç»œ",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "60",
        #            "--learning_rate", "0.0012",  # ç¨é«˜å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "128",      # ä¸¤å±‚LSTMç›¸åŒå¤§å°
        #            "--ff_hidden", "64",          # æ›´å¤§å‰é¦ˆå±‚
        #            "--dropout_lstm", "0.25",     # ç¨ä½dropout
        #            "--rbm_pool", "mean",         # å°è¯•å‡å€¼æ± åŒ–
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "4",
        #            "--rbm_lr", "0.008",          # ç¨é«˜RBMå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-4: é«˜å­¦ä¹ ç‡é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "160",        # æ›´å¤§batch
        #            "--epochs", "50",
        #            "--learning_rate", "0.0015",  # æ›´é«˜å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.2",      # æ›´ä½dropout
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "3",          # è¾ƒå°‘é¢„è®­ç»ƒè½®æ•°
        #            "--rbm_lr", "0.01",           # è¾ƒé«˜RBMå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-5: æ— é¢„è®­ç»ƒåŸºçº¿",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "60",
        #            "--learning_rate", "0.001",
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.3",
        #            "--rbm_pool", "last",
        #            # ä¸å¯ç”¨RBMé¢„è®­ç»ƒ
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM-6: Cosineè°ƒåº¦å™¨",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",             # æ›´å¤šè½®æ•°é…åˆcosine
        #            "--learning_rate", "0.002",   # æ›´é«˜åˆå§‹å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",
        #            "--lstm_hidden1", "128",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "32",
        #            "--dropout_lstm", "0.35",
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "5",
        #            "--rbm_lr", "0.005",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "cosine",      # ä½¿ç”¨cosineè°ƒåº¦å™¨
        #            "--early_stopping", "15"
        #            ]
        #         },
        
        # # TSMixer ä¼˜åŒ–å®éªŒ - åŸºäºæ—¥å¿—åˆ†æ
        # {
        #     "name": "TSMixer-1: æœ€ä¼˜åŸºçº¿é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "60",
        #            "--learning_rate", "0.002",      # éªŒè¯æœ‰æ•ˆçš„é«˜å­¦ä¹ ç‡
        #            "--tsmixer_layers", "4",         # æœ€ä½³å±‚æ•°
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.1",              # è¾ƒä½dropout
        #            "--scheduler", "plateau",        # æœ€ä½³è°ƒåº¦å™¨
        #            "--early_stopping", "5"          # ç¨å¾®å¢åŠ è€å¿ƒå€¼
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-2: å¼ºæ­£åˆ™åŒ–é…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",           # å‡å°batch size
        #            "--epochs", "60",
        #            "--learning_rate", "0.0015",     # ç¨ä½å­¦ä¹ ç‡
        #            "--weight_decay", "0.0005",      # å¢å¼ºæƒé‡è¡°å‡
        #            "--tsmixer_layers", "4",
        #            "--time_expansion", "3",         # å‡å°‘å¤æ‚åº¦
        #            "--feat_expansion", "3",
        #            "--dropout", "0.2",              # æ›´å¼ºdropout
        #            "--scheduler", "plateau",
        #            "--early_stopping", "8"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-3: æ·±å±‚ç½‘ç»œé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "192",
        #            "--epochs", "80",
        #            "--learning_rate", "0.001",      # æ·±å±‚ç½‘ç»œç”¨è¾ƒä½å­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "6",         # æ›´æ·±ç½‘ç»œ
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.15",
        #            "--scheduler", "onecycle",       # æ·±å±‚ç½‘ç»œé€‚åˆonecycle
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-4: ä¿å®ˆè®­ç»ƒé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0008",     # ä¿å®ˆå­¦ä¹ ç‡
        #            "--weight_decay", "0.0003",
        #            "--tsmixer_layers", "3",         # è¾ƒæµ…ç½‘ç»œ
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.25",             # å¼ºæ­£åˆ™åŒ–
        #            "--scheduler", "cosine",         # é•¿æœŸè®­ç»ƒç”¨cosine
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-5: é«˜æ•ˆå¿«é€Ÿé…ç½®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "384",           # å¤§batchå¿«é€Ÿè®­ç»ƒ
        #            "--epochs", "40",                # è¾ƒå°‘è½®æ•°
        #            "--learning_rate", "0.003",      # æ›´é«˜å­¦ä¹ ç‡å¿«é€Ÿæ”¶æ•›
        #            "--weight_decay", "0.0001",
        #            "--tsmixer_layers", "4",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.1",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "3"          # æ¿€è¿›æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "TSMixer-6: FD002å¤æ‚æ•°æ®",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.001",      # FD002ç”¨è¾ƒä¿å®ˆå‚æ•°
        #            "--weight_decay", "0.0005",
        #            "--tsmixer_layers", "5",         # å¤æ‚æ•°æ®éœ€è¦æ›´å¤šå±‚
        #            "--time_expansion", "6",
        #            "--feat_expansion", "5",
        #            "--dropout", "0.2",              # æ›´å¼ºæ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # ============================================================================
        # TSMixer ä¼˜åŒ–å®éªŒ - åŸºäºæ—¥å¿—åˆ†æçš„æ–°é…ç½®
        # ============================================================================
        
        # {
        #     "name": "TSMixer + FD001 (æ·±å±‚ä¼˜åŒ–é…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0012",
        #            "--weight_decay", "0.0002",
        #            "--tsmixer_layers", "8",         # æ›´æ·±çš„ç½‘ç»œ
        #            "--time_expansion", "6",         # æ›´å¤§çš„æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "4",
        #            "--dropout", "0.12",             # ç²¾è°ƒçš„dropout
        #            "--scheduler", "onecycle",       # æœ€ä½³è°ƒåº¦å™¨
        #            "--early_stopping", "12"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (å¿«é€Ÿé«˜æ•ˆé…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "512",           # å¤§æ‰¹é‡
        #            "--epochs", "60",
        #            "--learning_rate", "0.004",      # é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.0001",
        #            "--tsmixer_layers", "5",
        #            "--time_expansion", "4",
        #            "--feat_expansion", "5",         # å¹³è¡¡çš„æ‰©å±•
        #            "--dropout", "0.08",             # ä½dropout
        #            "--scheduler", "plateau",
        #            "--early_stopping", "5"
        #            ]
        # },
        
        # {
        #     "name": "TSMixer + FD001 (ææ·±ç½‘ç»œæµ‹è¯•)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "192",
        #            "--epochs", "120",
        #            "--learning_rate", "0.001",
        #            "--weight_decay", "0.0003",
        #            "--tsmixer_layers", "10",        # ææ·±ç½‘ç»œ
        #            "--time_expansion", "5",
        #            "--feat_expansion", "4",
        #            "--dropout", "0.15",             # é€‚ä¸­æ­£åˆ™åŒ–
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "15"
        #            ]
        # },
        
        # ============================================================================
        # å‰ä¸‰åæœ€ä¼˜é…ç½® - åŸºäº13ä¸ªå®éªŒçš„æ€§èƒ½åˆ†æ
        # ============================================================================
        
        # {
        #     "name": "ğŸ¥‡ TSMixerå† å†›é…ç½® (11.46 RMSE)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "384",           # å¤§æ‰¹é‡è®­ç»ƒ
        #            "--epochs", "50",
        #            "--learning_rate", "0.005",      # æé«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.00005",     # æä½æƒé‡è¡°å‡
        #            "--tsmixer_layers", "4",         # è½»é‡ç½‘ç»œ
        #            "--time_expansion", "3",         # é€‚ä¸­æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "4",         # é€‚ä¸­ç‰¹å¾æ‰©å±•
        #            "--dropout", "0.05",             # æä½dropout
        #            "--scheduler", "plateau",        # å¹³å°è°ƒåº¦å™¨
        #            "--early_stopping", "10"          # æ¿€è¿›æ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¥ˆ TSMixeräºšå†›é…ç½® (11.69 RMSE)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "512",           # è¶…å¤§æ‰¹é‡
        #            "--epochs", "60",
        #            "--learning_rate", "0.004",      # é«˜å­¦ä¹ ç‡
        #            "--weight_decay", "0.0001",      # ä½æƒé‡è¡°å‡
        #            "--tsmixer_layers", "5",         # ä¸­ç­‰æ·±åº¦
        #            "--time_expansion", "4",         # å¹³è¡¡æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "5",         # è¾ƒå¤§ç‰¹å¾æ‰©å±•
        #            "--dropout", "0.08",             # ä½dropout
        #            "--scheduler", "plateau",        # å¹³å°è°ƒåº¦å™¨
        #            "--early_stopping", "10"          # å¿«é€Ÿæ—©åœ
        #            ]
        # },
        
        # {
        #     "name": "ğŸ¥‰ TSMixerå­£å†›é…ç½® (11.91 RMSE)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",           # ä¸­ç­‰æ‰¹é‡
        #            "--epochs", "100",               # æ›´å¤šè®­ç»ƒè½®æ•°
        #            "--learning_rate", "0.0012",     # ç²¾è°ƒå­¦ä¹ ç‡
        #            "--weight_decay", "0.0002",      # é€‚ä¸­æƒé‡è¡°å‡
        #            "--tsmixer_layers", "8",         # æ·±å±‚ç½‘ç»œ
        #            "--time_expansion", "6",         # å¤§æ—¶é—´æ‰©å±•
        #            "--feat_expansion", "4",         # é€‚ä¸­ç‰¹å¾æ‰©å±•
        #            "--dropout", "0.12",             # é€‚ä¸­dropout
        #            "--scheduler", "onecycle",       # OneCycleè°ƒåº¦å™¨
        #            "--early_stopping", "12"         # è€å¿ƒæ—©åœ
        #            ]
        # },
        
        # ============================================================================
        # CNN-TSMixer å®éªŒé…ç½® - æ–°çš„æ··åˆæ¶æ„
        # ============================================================================
        
        # {
        #     "name": "ğŸš€ CNN-TSMixer + FD001 (åŸºç¡€é…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "cnn_tsmixer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "50",
        #            "--learning_rate", "0.001",
        #            "--weight_decay", "0.0001",
        #            # CNN-TSMixerç‰¹å®šå‚æ•°
        #            "--patch", "5",
        #            "--cnn_channels", "64",
        #            "--cnn_layers", "2",
        #            "--cnn_kernel", "5",
        #            "--d_model", "128",
        #            "--depth", "4",
        #            "--token_mlp_dim", "256",
        #            "--channel_mlp_dim", "128",
        #            "--dropout", "0.10",
        #            "--cnn_pool", "mean",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        
        # {
        #     "name": "RBM-LSTM + FD001 (æ— é¢„è®­ç»ƒåŸºçº¿)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "60",
        #            "--learning_rate", "0.0003",  # è®ºæ–‡å»ºè®®çš„AdamWå­¦ä¹ ç‡
        #            "--rbm_hidden", "64",
        #            "--lstm_hidden1", "64",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "8",
        #            "--dropout_lstm", "0.5",
        #            "--rbm_pool", "last",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "7"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM + FD001 (RBMé¢„è®­ç»ƒ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "30",            # å‡å°‘epochsä¾¿äºæµ‹è¯•
        #            "--learning_rate", "0.0003",
        #            "--rbm_hidden", "64",
        #            "--lstm_hidden1", "64",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "8",
        #            "--dropout_lstm", "0.5",
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",  # å¯ç”¨RBMé¢„è®­ç»ƒ
        #            "--rbm_epochs", "3",      # RBMé¢„è®­ç»ƒè½®æ•°
        #            "--rbm_lr", "0.01",       # RBMé¢„è®­ç»ƒå­¦ä¹ ç‡
        #            "--rbm_cd_k", "1",        # å¯¹æ¯”æ•£åº¦æ­¥æ•°
        #            "--scheduler", "plateau",
        #            "--early_stopping", "7"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM + FD001 (å¤§æ¨¡å‹+é¢„è®­ç»ƒ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0002",  # å¤§æ¨¡å‹ç”¨è¾ƒå°å­¦ä¹ ç‡
        #            "--rbm_hidden", "128",         # æ›´å¤§çš„RBMéšè—å±‚
        #            "--lstm_hidden1", "128",       # æ›´å¤§çš„LSTMå±‚
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "16",           # æ›´å¤§çš„å‰é¦ˆå±‚
        #            "--dropout_lstm", "0.6",       # æ›´å¼ºçš„æ­£åˆ™åŒ–
        #            "--rbm_pool", "mean",          # å°è¯•å¹³å‡æ± åŒ–
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "5",           # æ›´å¤šé¢„è®­ç»ƒè½®æ•°
        #            "--rbm_lr", "0.008",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "RBM-LSTM + FD002 (å¤æ‚æ•°æ®+é¢„è®­ç»ƒ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "rbmlstm", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0002",
        #            "--rbm_hidden", "96",
        #            "--lstm_hidden1", "96",
        #            "--lstm_hidden2", "64",
        #            "--ff_hidden", "12",
        #            "--dropout_lstm", "0.6",       # FD002æ›´å¤æ‚ï¼Œéœ€è¦æ›´å¼ºæ­£åˆ™åŒ–
        #            "--rbm_pool", "last",
        #            "--enable_rbm_pretrain",
        #            "--rbm_epochs", "4",
        #            "--rbm_lr", "0.01",
        #            "--rbm_cd_k", "1",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "8"
        #            ]
        # },

        # BiLSTMå®éªŒï¼ˆæ³¨é‡Šæ‰ä»¥ä¾¿ä¸“æ³¨æµ‹è¯•RBM-LSTMï¼‰
        # {
        #     "name": "BiLSTM + FD001 (åŸºç¡€é…ç½®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "bilstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "60",
        #            "--learning_rate", "0.001",
        #            "--lstm_hidden", "64",
        #            "--lstm_layers", "2",
        #            "--bidirectional",  # åŒå‘LSTM
        #            "--mlp_hidden", "64",
        #            "--lstm_pool", "last",
        #            "--dropout", "0.1",
        #            "--scheduler", "plateau",
        #            "--early_stopping", "7"
        #            ]
        # },
        
        # {
        #     "name": "BiLSTM + FD001 (æ·±å±‚ç½‘ç»œ)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "bilstm", 
        #            "--fault", "FD001", 
        #            "--batch_size", "128",
        #            "--epochs", "80",
        #            "--learning_rate", "0.0008",
        #            "--lstm_hidden", "128",  # æ›´å¤§çš„éšè—å±‚
        #            "--lstm_layers", "3",    # æ›´å¤šå±‚æ•°
        #            "--bidirectional",
        #            "--mlp_hidden", "128",
        #            "--lstm_pool", "mean",   # å¹³å‡æ± åŒ–
        #            "--dropout", "0.15",
        #            "--scheduler", "onecycle",
        #            "--early_stopping", "10"
        #            ]
        # },
        
        # {
        #     "name": "BiLSTM + FD002 (å¤æ‚æ•°æ®)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "bilstm", 
        #            "--fault", "FD002", 
        #            "--batch_size", "128",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0005",
        #            "--lstm_hidden", "96",
        #            "--lstm_layers", "2",
        #            "--bidirectional",
        #            "--mlp_hidden", "96",
        #            "--lstm_pool", "last",
        #            "--dropout", "0.2",
        #            "--scheduler", "cosine",
        #            "--early_stopping", "8"
        #            ]
        # },

        
        # {
        #     "name": "Transformer + FD001 (å°æ¨¡å‹)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "transformer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "100",
        #            "--learning_rate", "0.0003",
        #            "--d_model", "128",
        #            "--nhead", "8",
        #            "--num_layers", "6",
        #            ]
        # },
        
        # {
        #     "name": "Transformer + FD001 (ä¸­ç­‰æ¨¡å‹)",
        #     "cmd": ["python", "train.py", 
        #            "--model", "transformer", 
        #            "--fault", "FD001", 
        #            "--batch_size", "256",
        #            "--epochs", "30",
        #            "--learning_rate", "0.0003",
        #            "--d_model", "128",
        #            "--nhead", "4",
        #            "--num_layers", "3",
        #            ]
        # },
        
       
        # {
        #     "name": "Transformer + FD002",
        #     "cmd": ["python", "train.py", 
        #            "--model", "transformer", 
        #            "--fault", "FD002", 
        #            "--batch_size", "256",
        #            "--epochs", "40",  # FD002æ›´å¤æ‚ï¼Œéœ€è¦æ›´å¤šè½®æ¬¡
        #            "--learning_rate", "0.0002",  # ç¨å¾®é™ä½å­¦ä¹ ç‡
        #            "--d_model", "128",
        #            "--nhead", "4",
        #            "--num_layers", "3",
        #            ]
        # }
    ]
    
    print("å¼€å§‹æ‰¹é‡å®éªŒ...")
    results = {}
    
    for i, exp in enumerate(experiments, 1):
        print(f"\n\nğŸš€ å®éªŒ {i}/{len(experiments)}: {exp['name']}")
        
        success = run_command(exp["cmd"])
        results[exp["name"]] = "æˆåŠŸ" if success else "å¤±è´¥"
        
        if not success:
            print(f"âŒ å®éªŒå¤±è´¥: {exp['name']}")
            choice = input("ç»§ç»­ä¸‹ä¸€ä¸ªå®éªŒï¼Ÿ(y/n): ").lower()
            if choice != 'y':
                break
        else:
            print(f"âœ… å®éªŒæˆåŠŸ: {exp['name']}")
    
    # æ‰“å°æ€»ç»“
    print(f"\n\n{'='*60}")
    print("å®éªŒæ€»ç»“:")
    print('='*60)
    for name, status in results.items():
        status_icon = "âœ…" if status == "æˆåŠŸ" else "âŒ"
        print(f"{status_icon} {name}: {status}")


if __name__ == "__main__":
    main()
