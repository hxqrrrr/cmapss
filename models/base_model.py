# base_model.py
import torch
import torch.nn as nn
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any, Tuple
import numpy as np


class BaseRULModel(ABC):
    """
    æŠ½è±¡åŸºç±»ï¼šç»Ÿä¸€RULé¢„æµ‹æ¨¡åž‹çš„æŽ¥å£
    æ‰€æœ‰å­ç±»å¿…é¡»å®žçŽ°è¿™äº›æ–¹æ³•ï¼Œä¿è¯åŠŸèƒ½ä¸€è‡´
    """

    def __init__(self, input_size: int, seq_len: int, out_channels: int = 1):
        self.input_size = input_size
        self.seq_len = seq_len
        self.out_channels = out_channels
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model: Optional[nn.Module] = None
        self.optimizer: Optional[torch.optim.Optimizer] = None
        self.scheduler: Optional[Any] = None
        self.best_metrics: Dict[str, float] = {}  # å­˜å‚¨æœ€ä½³è®­ç»ƒæŒ‡æ ‡

    # --------- å¿…é¡»ç”±å­ç±»å®žçŽ°çš„æ–¹æ³• ---------
    @abstractmethod
    def build_model(self) -> nn.Module:
        """å®šä¹‰å…·ä½“æ¨¡åž‹ç»“æž„ (nn.Module)"""
        pass

    @abstractmethod
    def compile(self, learning_rate: float, weight_decay: float, **kwargs):
        """è®¾å®šä¼˜åŒ–å™¨ & è°ƒåº¦å™¨"""
        pass

    def train_model(self, train_loader, val_loader=None,
               criterion: Optional[Any] = None, epochs: int = 20,
               test_dataset_for_last=None, early_stopping_patience=7):
        """é»˜è®¤è®­ç»ƒæµç¨‹ï¼Œå­ç±»å¯é‡å†™
        
        Returns:
            dict: åŒ…å«æœ€ä½³éªŒè¯æ€§èƒ½çš„å­—å…¸ï¼Œå¦‚æžœå¯ç”¨æ—©åœåˆ™è¿”å›žæœ€ä½³ç»“æžœï¼Œå¦åˆ™è¿”å›žæœ€ç»ˆç»“æžœ
        """
        if criterion is None:
            criterion = nn.MSELoss()

        # æ—©åœæœºåˆ¶
        best_val_loss = float('inf')
        patience_counter = 0
        best_epoch = 0
        
        self.model.train()
        for epoch in range(1, epochs + 1):
            running_loss = 0.0
            for data, target in train_loader:
                data, target = self.to_device(data, target)
                target = target.view(-1)

                self.optimizer.zero_grad(set_to_none=True)
                pred = self.model(data).view(-1)
                loss = criterion(pred, target)
                loss.backward()
                nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
                self.optimizer.step()

                if self.scheduler is not None:
                    if hasattr(self.scheduler, "step") and not isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                        self.scheduler.step()

                running_loss += loss.item()

            # è®­ç»ƒæŸå¤±
            train_rmse = (running_loss / max(1, len(train_loader))) ** 0.5
            
            # éªŒè¯å…¨å±€RMSE
            val_rmse_global = float('nan')
            if val_loader is not None:
                val_results = self.evaluate(val_loader)
                val_rmse_global = val_results.get('rmse', float('nan'))
            
            # æœ€åŽçª—å£RMSEå’ŒScore
            val_rmse_last, val_score_last = float('nan'), float('nan')
            if test_dataset_for_last is not None:
                val_rmse_last, val_score_last = self.evaluate_last_window(test_dataset_for_last)
            
            # ç¡®ä¿æ¨¡åž‹å›žåˆ°è®­ç»ƒæ¨¡å¼ï¼ˆé‡è¦ï¼šLSTMç­‰RNNæ¨¡åž‹éœ€è¦è¿™ä¸ªï¼‰
            # åœ¨éªŒè¯åŽé‡æ–°è®¾ç½®è®­ç»ƒæ¨¡å¼ï¼Œå¯¹æ‰€æœ‰æ¨¡åž‹éƒ½æ˜¯å®‰å…¨çš„
            self.model.train()
            
            # èŽ·å–å­¦ä¹ çŽ‡
            lr = self.optimizer.param_groups[0]["lr"] if self.optimizer else 0.0
            
            # ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼ - æ¯ä¸ªæ¨¡åž‹éƒ½å¿…é¡»è®°å½•è¿™äº›æŒ‡æ ‡
            self.log_training_metrics(epoch, epochs, train_rmse, val_rmse_global, 
                                    val_rmse_last, val_score_last, lr)
            
            # ReduceLROnPlateauè°ƒåº¦å™¨éœ€è¦åœ¨epochç»“æŸåŽæ›´æ–°
            if self.scheduler is not None and isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                metric = val_rmse_last if not torch.isnan(torch.tensor(val_rmse_last)) else val_rmse_global
                if not torch.isnan(torch.tensor(metric)):
                    self.scheduler.step(metric)
            
            # æ—©åœæœºåˆ¶ï¼ˆä»…åœ¨early_stopping_patience > 0æ—¶å¯ç”¨ï¼‰
            if early_stopping_patience > 0:
                current_val_loss = val_rmse_last if not torch.isnan(torch.tensor(val_rmse_last)) else val_rmse_global
                if not torch.isnan(torch.tensor(current_val_loss)):
                    if current_val_loss < best_val_loss:
                        best_val_loss = current_val_loss
                        patience_counter = 0
                        best_epoch = epoch
                        
                        # ä¿å­˜æœ€ä½³æŒ‡æ ‡
                        self.best_metrics = {
                            'train_rmse': train_rmse,
                            'val_rmse_global': val_rmse_global,
                            'val_rmse_last': val_rmse_last,
                            'val_score_last': val_score_last,
                            'best_epoch': epoch,
                            'learning_rate': lr
                        }
                        
                        print(f"ðŸ“ˆ New best validation RMSE: {best_val_loss:.4f}")
                    else:
                        patience_counter += 1
                        if patience_counter >= early_stopping_patience:
                            print(f" Early stopping triggered after {epoch} epochs (patience: {early_stopping_patience})")
                            print(f" Best validation RMSE: {best_val_loss:.4f}")
                            break
        
        # è¿”å›žæœ€ä½³éªŒè¯ç»“æžœ
        if early_stopping_patience > 0 and best_val_loss != float('inf'):
            return {
                "best_val_rmse": best_val_loss, 
                "early_stopped": True,
                "best_epoch": best_epoch
            }
        else:
            # å¦‚æžœæ²¡æœ‰æ—©åœæˆ–æ²¡æœ‰éªŒè¯æ•°æ®ï¼Œè¿”å›žæœ€ç»ˆéªŒè¯ç»“æžœ
            final_results = {}
            if val_loader is not None:
                final_val_results = self.evaluate(val_loader)
                final_results["final_val_rmse"] = final_val_results.get('rmse', float('nan'))
                
                # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
                self.best_metrics = {
                    'train_rmse': train_rmse,
                    'val_rmse_global': final_val_results.get('rmse', float('nan')),
                    'val_rmse_last': val_rmse_last,
                    'val_score_last': val_score_last,
                    'final_epoch': epochs,
                    'learning_rate': lr
                }
                
            final_results["early_stopped"] = False
            return final_results

    def evaluate(self, test_loader) -> Dict[str, float]:
        """é»˜è®¤æµ‹è¯•é›†è¯„ä¼°"""
        self.model.eval()
        mse, n = 0.0, 0
        with torch.no_grad():
            for data, target in test_loader:
                data, target = self.to_device(data, target)
                target = target.view(-1)
                pred = self.model(data).view(-1)
                mse += torch.sum((pred - target) ** 2).item()
                n += target.numel()
        rmse = (mse / max(1, n)) ** 0.5
        return {"rmse": rmse}


    # --------- é€šç”¨å·¥å…·å‡½æ•° (å­ç±»å¯å¤ç”¨) ---------
    def to_device(self, data, target):
        """ç»Ÿä¸€çš„æ•°æ®è¿ç§»æŽ¥å£"""
        data = data.to(self.device, non_blocking=True)
        target = target.to(self.device, non_blocking=True)
        return data, target

    def log_training_metrics(self, epoch: int, total_epochs: int, 
                           train_rmse: float, val_rmse_global: float,
                           val_rmse_last: float, val_score_last: float, lr: float):
        """
        ç»Ÿä¸€çš„è®­ç»ƒæŒ‡æ ‡æ—¥å¿—è®°å½•æ ¼å¼ - æ¯ä¸ªæ¨¡åž‹éƒ½å¿…é¡»è®°å½•è¿™äº›æŒ‡æ ‡
        Args:
            epoch: å½“å‰è½®æ¬¡
            total_epochs: æ€»è½®æ¬¡
            train_rmse: è®­ç»ƒé›†RMSE
            val_rmse_global: éªŒè¯é›†å…¨å±€RMSE (cycles)
            val_rmse_last: éªŒè¯é›†æœ€åŽçª—å£RMSE (cycles) 
            val_score_last: éªŒè¯é›†æœ€åŽçª—å£PHM08 Score
            lr: å½“å‰å­¦ä¹ çŽ‡
        """
        import logging
        logger = logging.getLogger(__name__)
        
        # æ ¼å¼åŒ–æ•°å€¼æ˜¾ç¤º
        def format_metric(val):
            if np.isnan(val) or val == float('nan'):
                return "N/A"
            return f"{val:.2f}"
        
        # è¯¦ç»†çš„æ—¥å¿—æ ¼å¼
        metrics_msg = (f"[Epoch {epoch:3d}/{total_epochs}] "
                      f"train_rmse={format_metric(train_rmse)} | "
                      f"val_rmse(global)={format_metric(val_rmse_global)} cycles | "
                      f"val_rmse(last)={format_metric(val_rmse_last)} cycles | "
                      f"val_score(last)={format_metric(val_score_last)} | "
                      f"lr={lr:.2e}")
        
        # åŒæ—¶è¾“å‡ºåˆ°æŽ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶
        print(metrics_msg)
        logger.info(metrics_msg)

    # ç§»é™¤æ¨¡åž‹ä¿å­˜å’ŒåŠ è½½åŠŸèƒ½

    # --------- è¯„ä¼°ç›¸å…³å·¥å…·å‡½æ•° ---------
    @staticmethod
    def rmse_score(pred: torch.Tensor, target: torch.Tensor) -> float:
        """è®¡ç®— RMSE"""
        d = (pred - target).detach().cpu().numpy()
        return float(np.sqrt((d ** 2).mean()))

    @staticmethod
    def phm08_score(pred: torch.Tensor, target: torch.Tensor, clip_max: float = 125.0) -> float:
        """PHM08ç«žèµ›é£Žæ ¼çš„éžå¯¹ç§°è¯„åˆ†å‡½æ•°"""
        pred = torch.clamp(pred, max=clip_max).detach().cpu().numpy()
        target = torch.clamp(target, max=clip_max).detach().cpu().numpy()
        d = pred - target
        score = np.sum(np.where(d > 0, np.exp(d / 10.0) - 1.0, np.exp(-d / 13.0) - 1.0))
        return float(score)

    @torch.no_grad()
    def evaluate_last_window(self, test_dataset, clip_max: float = 125.0) -> Tuple[float, float]:
        """
        æ¯å°æµ‹è¯•å‘åŠ¨æœºå–æœ€åŽä¸€ä¸ªçª—å£ï¼Œè¿”å›ž (RMSE, Score)
        """
        self.model.eval()
        last_preds, last_targets = [], []

        for uid in test_dataset.units:
            unit_indices = [i for i, (u, _) in enumerate(test_dataset.sample_index) if u == uid]
            if unit_indices:
                x, y = test_dataset[unit_indices[-1]]
                x = x.unsqueeze(0).to(self.device)   # (1,L,C)
                pred = self.model(x)                 # (1,)
                last_preds.append(float(pred.item()))
                last_targets.append(float(y.item()))

        if last_preds:
            pred_t = torch.tensor(last_preds)
            target_t = torch.tensor(last_targets)
            rmse = self.rmse_score(pred_t, target_t)
            score = self.phm08_score(pred_t, target_t, clip_max=clip_max)
            return rmse, score
        else:
            return float("nan"), float("nan")

    # --------- å¸¸ç”¨æŸå¤±å‡½æ•°ï¼ˆå¯é€‰ï¼‰ ---------
    @staticmethod
    def weighted_mse_phm_like(pred, y, norm_scale=125.0, normalized=True):
        """
        å¯¹ MSE æŒ‰ PHM08 ä¸å¯¹ç§°ä»£ä»·åŠ æƒï¼š
        err>0 (æ™šæŠ¥):  weight = exp(err / (10/norm_scale))
        err<=0 (æ—©æŠ¥): weight = exp(-err / (13/norm_scale))
        """
        if normalized:
            pos_k, neg_k = 10.0 / norm_scale, 13.0 / norm_scale
        else:
            pos_k, neg_k = 10.0, 13.0
        err = pred - y
        w = torch.where(err > 0, torch.exp(err / pos_k), torch.exp(-err / neg_k))
        return (w * err.pow(2)).mean()
